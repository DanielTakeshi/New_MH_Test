<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"><title>
	Reviews For Paper
</title>
<style>
body
{
	font-family:verdana,arial,helvetica;
}
#header
{
    width: 100%;
    font-size: small;
    background-color:#F7F7F7;
}
.headerSeparator
{
    background-color: #105586;
}
.printThemeText
{
    font-size:small;
}
.printThemeTable td
{
    vertical-align:top;
}
.printThemeGrid th
{
    color:white;
    background:#5D7B9D;
    font-weight:bold;
}
.printThemeGrid
{
    border-collapse:collapse;
}
.printThemeGrid td, .printThemeGrid th
{
    border:solid 1px #D6D3CE;
    padding:4px 4px 4px 4px;
}
.printThemeGrid .row
{ 
    background-color:#F7F6F3;
    color:#333333;
    vertical-align:top;
}
.printThemeGrid .altrow
{ 
    background-color:White;
    color:#284775;
    vertical-align:top;
}
.cellprompt
{
	font-weight:bold;
	white-space:nowrap;
    width:100px;	
}
.paperHeader
{
    background-color:#dee3e7;
    margin:5px 5px 15px 0px;
    width:99%;
    font-family:Verdana;
    font-size:medium;
    font-weight:bold;
}
.sectionHeader
{
    background-color:#dee3e7;
    padding:5px 5px 5px 0px;
    width:99%;
    text-decoration:underline;
    font-family:Verdana;
    font-size:small;
    font-weight:bold;
}
.underlineheader
{
    text-decoration:underline;
    font-weight:bold;
    padding:5px 0px;
}
.response
{
    padding:5px 0px;
}
.reviewerlabel
{
    padding-right:20px;
}
.pageTitle
{
    background-color:#dee3e7;
    padding:5px 5px 5px 5px;
    margin-top:10px;
    width:99%;
    font-family:Verdana;
    font-size:medium;
    font-weight:bold;
}
.submissionDetailsView
{
}
.submissionDetailsView tr
{
    vertical-align:top;
}
.submissionDetailsView td.prompt
{
    font-weight:bold;
}
.submissionDetailsView tr.sectionSeparator
{

}
.submissionDetailsView tr.sectionSeparator td
{
    background-color:#dee3e7;
    padding:5px 5px 5px 5px;
    font-family:Verdana;
    font-size:small;
    font-weight:bold;
    color:Navy;
}
/*CSS Grid View General Definitions*/
.CssGridView
{
    font-size:small; 
}

.CssGridView td, .CssGridView th
{
    padding:4px 4px 4px 4px;
}

/*CSS Compact Grid View General Definitions*/
.CssGridViewCompact img
{
    border-style:none;
    border-width:0px;
}

.CssGridViewCompact
{
    font-size:1em;
    border-style:solid;
    border-color:#D6D3CE;
    border-width:1px;
}

.CssGridViewCompact .hrow a
{
    font-size:1em;
}

.CssGridViewCompact .row a, .CssGridViewCompact .altrow a
{
    font-size:0.8em;
}

.CssGridViewCompact .row .normal a, .CssGridViewCompact .row .normal, .CssGridViewCompact .altrow .normal a, .CssGridViewCompact .altrow .normal
{
    font-size:1em;
}

/*CSS Grid View Header Styles*/
.CssGridView .hrow, .CssGridViewCompact .hrow
{ 
    background-color:#5D7B9D;
    font-weight:bold;
    color:White;
}


.CssGridViewCompact .hrow td
{ 
    border-bottom-width:0px;
}

.CssGridViewCompact .hrow th
{ 
    border-top-width:0px;
    font-size:0.8em;
    vertical-align:top;
    border-left-width:0px;
    border-right-width:0px;
}

.CssGridViewCompact .smaller
{
    font-size:0.8em;
}

/*CSS Grid View Row Styles*/
.CssGridViewCompact .row, .CssGridViewCompact .altrow
{
    border-top-style:solid;
    border-top-color:#D6D3CE;
    border-top-width:1px;
    border-bottom-style:solid;
    border-bottom-color:#D6D3CE;
    border-bottom-width:1px;
}

/*CSS Grid View Header Styles*/
.CssGridViewCompact .hrow .leftborder, .CssGridViewCompact .row .leftborder, .CssGridViewCompact .altrow .leftborder
{
    border-left-width:1px;
    border-left-color:#D6D3CE;
    border-left-style:solid;
}

.CssGridViewCompact .hrow .rightborder, .CssGridViewCompact .row .rightborder, .CssGridViewCompact .altrow .rightborder
{
    border-right-width:1px;
    border-right-color:#D6D3CE;
    border-right-style:solid;
}

.CssGridView .hrow a, .CssGridViewCompact .hrow a
{ 
    color:White;
}
 
.CssGridView .row, .CssGridViewCompact .row
{ 
    background-color:#F7F6F3;
    color:#333333;
    vertical-align:top;
}

.CssGridView .altrow, .CssGridViewCompact .altrow
{ 
    vertical-align:top;
}

.CssGridViewCompact .row td
{ 
    border-left-width:0px;
    border-right-width:0px;
}
 
.CssGridViewCompact .altrow
{ 
    background-color:White;
    color:#284775;
    vertical-align:top;
}

.CssGridView .altrow tr, .CssGridViewCompact .altrow tr, .CssGridView .row tr, .CssGridViewCompact .row tr
{ 
    vertical-align:top;
}
</style>
</head>
<body>
<form name="aspnetForm" method="post" action="./ViewReviewsForPaper.aspx?paperId=1035" id="aspnetForm">
<div>
<input name="__VIEWSTATE" id="__VIEWSTATE" value="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" type="hidden">
</div>

<div>

	<input name="__VIEWSTATEGENERATOR" id="__VIEWSTATEGENERATOR" value="93D783A2" type="hidden">
</div>
<table id="header">
<tbody><tr>
<td width="100%"><a href="https://nips.cc/" target="_blank">NIPS 2016</a><br><b>Neural Information Processing Systems 2016</b><br>December 05 - 10, 2016, Barcelona, Spain</td>
</tr>
<tr class="headerSeparator">
    <td style="height:5px"></td>
</tr>
</tbody></table>
<table id="content"><tbody><tr><td class="contentBorder">&nbsp;</td><td class="contentContainer">
<span id="ctl00_cph_Label4" style="font-size:Small;font-weight:bold;">Reviews For Paper</span>
<span id="ctl00_cph_lblErrorMessage" class="error" style="font-size:Small;"></span>
<div id="ctl00_cph_pnlReviews">
	
    <span style="font-size:Small;"><table id="ctl00_cph_infoSubmission_tblInfo" class="nicetable2" style="text-align:left; width: 100%;">
		<tbody><tr>
			<td width="100px"><b>Paper ID</b></td>
			<td><span id="ctl00_cph_infoSubmission_lblPaperId" style="font-size:Small;">1035</span></td>
		</tr>
		<tr>
			<td><b>Title</b></td>
			<td><span id="ctl00_cph_infoSubmission_lblPaperTitle" style="font-size:Small;">A Simple Minibatch Acceptance Test for MCMC</span></td>
		</tr>
	</tbody></table>
	</span>
    
    
            <hr>
            <table>
                <tbody><tr>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl00_Label2" style="font-size:Small;font-weight:bold;">Masked Reviewer ID:</span>
                    </td>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl00_Label1" style="font-size:Small;">Assigned_Reviewer_1</span>
                    </td>
                </tr>
                <tr>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl00_Label3" style="font-size:Small;font-weight:bold;">Review:</span>
                    </td>
                    <td>
                    </td>
                </tr>
            </tbody></table>
            <div>
		<table rules="all" style="color:#333333;border-width:1px;border-style:None;font-family:Verdana;font-size:Small;border-collapse:collapse;" border="1" cellpadding="4" cellspacing="0">
			<tbody><tr style="color:White;background-color:#5D7B9D;font-weight:bold;">
				<th scope="col">Question</th><th scope="col">&nbsp;</th>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Summary: Provide a brief summary of the contents of the paper.</td><td style="width:80%;">
                            The paper addresses MCMC for tall data 
problems, proposing a variant of the acceptance step of 
Metropolis-Hastings that only considers a subsample of the full dataset.<br>
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Fatal flaws: Does the paper have a "fatal 
flaw" making it unfit for publication, regardless of other criteria (may
 include out of scope, double publication, plagiarism, wrong proofs, 
flawed experiments)? Use the text box to justify your answer.</td><td style="width:80%;">
                            No (not as far as I can see)
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Technical quality: whether experimental methods are appropriate, proofs are sound, results are well analyzed.</td><td style="width:80%;">
                            2-Sub-standard for NIPS
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Novelty/originality: in any aspect of the work, theory, algorithm, applications, experimental.</td><td style="width:80%;">
                            3-Poster level (some notable novel contributions)
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Potential impact or usefulness: could be 
societal, academic, or practical and should be lasting in time, 
affecting a large number of people and/or bridge the gap between 
multiple disciplines.</td><td style="width:80%;">
                            3-Poster level (looks promising)
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Clarity and presentation: explanations, language and grammar, figures, graphs, tables, proper references.</td><td style="width:80%;">
                            2-Sub-standard for NIPS
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Qualitative assessment: Provide constructive 
feedback to the authors; justify and complement your ratings above. This
 is our MOST IMPORTANT QUESTION, we need to get good arguments for our 
decisions!</td><td style="width:80%;">
                            # Summary of the review<br>The topic of MCMC
 for big datasets is of importance, and the idea of swapping subsampling
 noise for acceptance noise is interesting, although not new, see below.
 My main concern is that paper is not clear nor technically sound enough
 for publication in NIPS. In particular, a more standard and detailed 
analysis is needed, see major comments below for hints.<br><br># Major comments<br>[BDH] = [Bardenet, Doucet and Holmes, MCMC for tall data, http://arxiv.org/abs/1505.02827].<br>- Section 2: there are a lot of uncited works, see e.g. the recent survey [BDH].<br>-
 L80 "hurt mixing": this is too vague, what does it hurt? Is geometric 
ergodicity not preserved, for example? Or does it increase asymptotic 
variance while preserving the type of ergodicity?<br>- Lemma 2 is too 
vague a statement to be a lemma. What does "approximately Gaussian" 
mean? Also, in the proof, a CLT for sampling without replacement is 
used, this requires a reference as it is nonstandard. Or is it because N
 is large that sampling without replacement is approximated with 
sampling with replacement?<br>- L132 "the noise means": this is unclear.<br>-
 Lemma 2: [BDH] warn against using CLT-based approximations in 
Metropolis-Hastings and give examples where the resulting algorithms 
perform worse than simple SGD. This should be commented. In particular, 
it feels a bit weird to assume n is large enough for a CLT (per MCMC 
iteration!) to hold, while we are trying to keep n low.<br>- Section 
3.2: the fact that part of the subsampling noise is transferred to the 
acceptance noise in Eqn (7) is interesting. This trick is not completely
 new though, see [BDH, Section 6.3] for instance.<br>- The decomposition in Eqn (6) is not unique, and is thus ill-defined.<br>- L136: X_norm and epsilon are both random variables, so I wouldn't use the term "estimate".<br>-
 Overall, Section 4 is confusing and should be rephrased. For instance, 
using P both for kernels and probability of accceptance is confusing. 
Same for notations such as a circle for the action of kernels on 
distributions.<br>- L201: who are the $\pi'_i$?<br>- It is hard for the 
reader to draw a conclusion from Section 4. Traditionally, this analysis
 section should first focus on whether the considered approximate 
algorithm has a limiting distribution, and then try to show a law of 
large numbers or a CLT, see e.g. [Douc, Moulines, Stoffer, Nonlinear 
time series, 2014, Sections 5-7]. This would be more informative.<br><br># Minor comments<br>- L63 "accepting if" -&gt; "if and only if".<br>- L285 a lot of references are lacking capitals.<br>
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Reviewer confidence regarding this review.</td><td style="width:80%;">
                            3-Expert (read the paper in detail, know the area, quite certain of my opinion)
                        </td>
			</tr>
		</tbody></table>
	</div>
            
        
            <hr>
            <table>
                <tbody><tr>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl01_Label2" style="font-size:Small;font-weight:bold;">Masked Reviewer ID:</span>
                    </td>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl01_Label1" style="font-size:Small;">Assigned_Reviewer_2</span>
                    </td>
                </tr>
                <tr>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl01_Label3" style="font-size:Small;font-weight:bold;">Review:</span>
                    </td>
                    <td>
                    </td>
                </tr>
            </tbody></table>
            <div>
		<table rules="all" style="color:#333333;border-width:1px;border-style:None;font-family:Verdana;font-size:Small;border-collapse:collapse;" border="1" cellpadding="4" cellspacing="0">
			<tbody><tr style="color:White;background-color:#5D7B9D;font-weight:bold;">
				<th scope="col">Question</th><th scope="col">&nbsp;</th>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Summary: Provide a brief summary of the contents of the paper.</td><td style="width:80%;">
                            The paper presents a new minibatch 
acceptance test for big data MCMC. The idea is to approximate a sampler 
using Baker acceptance probability instead of the standard MH acceptance
 probability. The key difference between this method and previous 
methods is that it relies on fixed-sized minibatches.
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Fatal flaws: Does the paper have a "fatal 
flaw" making it unfit for publication, regardless of other criteria (may
 include out of scope, double publication, plagiarism, wrong proofs, 
flawed experiments)? Use the text box to justify your answer.</td><td style="width:80%;">
                            No (not as far as I can see)
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Technical quality: whether experimental methods are appropriate, proofs are sound, results are well analyzed.</td><td style="width:80%;">
                            2-Sub-standard for NIPS
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Novelty/originality: in any aspect of the work, theory, algorithm, applications, experimental.</td><td style="width:80%;">
                            2-Sub-standard for NIPS
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Potential impact or usefulness: could be 
societal, academic, or practical and should be lasting in time, 
affecting a large number of people and/or bridge the gap between 
multiple disciplines.</td><td style="width:80%;">
                            2-Sub-standard for NIPS
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Clarity and presentation: explanations, language and grammar, figures, graphs, tables, proper references.</td><td style="width:80%;">
                            3-Poster level (good enough)
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Qualitative assessment: Provide constructive 
feedback to the authors; justify and complement your ratings above. This
 is our MOST IMPORTANT QUESTION, we need to get good arguments for our 
decisions!</td><td style="width:80%;">
                            * The paper presents a novel minibatch 
acceptance test for big data MCMC. The idea is to approximate a sampler 
using Baker acceptance probability instead of the standard MH acceptance
 probability. For information Lemma 1 is well-known in the MCMC 
literature and using g(delta)=(1+exp(-delta))^-1 has also already 
appeared; see e.g. Branke et al. Simulated Annealing in the Presence of 
Noise, J. Heuristics, 2008.<br><br>* The method is potentially 
interesting but I think it would have been interesting to better detail 
how Xcorr is estimated practically. Deconvolution can be quite tricky 
numerically and some regularization techniques are usually necessary; 
see e.g. papers by Aurore Delaigle.<br><br>* I wonder about the 
connections between your method and the method in the paper of Branke 
cited above; see Section 6.3. of arxiv:1505.02827 On MCMC for Tall Data.
 It'd be good to discuss the connections.<br><br>* I believe that the 
theoretical results presented in the paper do not hold if no additional 
assumption is made. In particular, it is implicitly assumed that the 
perturbed kernels admit invariant distribution. This is not a given and 
might not be true; see e.g. A. Lee and G.O. Roberts, On the stability of
 noisy Metropolis-Hastings algorithms, Stat &amp; Computing 2015. In 
this paper the authors exhibit examples where their noisy MH kernels are
 transient despite the ideal MH enjoying nice theoretical properties.<br><br>*
 It has been reported in Bardenet, Doucet &amp; Holmes ICML 2014 that 
subsampling-based MCMC kernels can behave poorly; see also 
arxiv:1505.02827. It would be interesting to investigate the behavior of
 your algorithm on their toy example.<br><br><br><br><br>
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Reviewer confidence regarding this review.</td><td style="width:80%;">
                            3-Expert (read the paper in detail, know the area, quite certain of my opinion)
                        </td>
			</tr>
		</tbody></table>
	</div>
            
        
            <hr>
            <table>
                <tbody><tr>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl02_Label2" style="font-size:Small;font-weight:bold;">Masked Reviewer ID:</span>
                    </td>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl02_Label1" style="font-size:Small;">Assigned_Reviewer_3</span>
                    </td>
                </tr>
                <tr>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl02_Label3" style="font-size:Small;font-weight:bold;">Review:</span>
                    </td>
                    <td>
                    </td>
                </tr>
            </tbody></table>
            <div>
		<table rules="all" style="color:#333333;border-width:1px;border-style:None;font-family:Verdana;font-size:Small;border-collapse:collapse;" border="1" cellpadding="4" cellspacing="0">
			<tbody><tr style="color:White;background-color:#5D7B9D;font-weight:bold;">
				<th scope="col">Question</th><th scope="col">&nbsp;</th>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Summary: Provide a brief summary of the contents of the paper.</td><td style="width:80%;">
                            This paper proposes a new approach to 
carrying out mini-batch based acceptance test for MCMC. It introduces a 
novel and interesting idea of absorbing the noise of the log-probability
 ratio estimate by decomposing the random variable X into a normal 
distribution and a correction term. Unfortunately, the proposed 
acceptance function mixes slower than the Metropolis acceptance 
function, the theoretical contribution is not rigorously proved, and the
 experiment setting is problematic and the result do not show convincing
 evidence that the proposed algorithm is better than the adaptive M-H 
test.
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Fatal flaws: Does the paper have a "fatal 
flaw" making it unfit for publication, regardless of other criteria (may
 include out of scope, double publication, plagiarism, wrong proofs, 
flawed experiments)? Use the text box to justify your answer.</td><td style="width:80%;">
                            Yes
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Explain fatal flaws if you ticked yes in the previous question.</td><td style="width:80%;">
                            The theoretical contribution is not 
rigorously proved. The experiment setting is problematic and the result 
do not show convincing evidence that the proposed algorithm is better 
than the adaptive M-H test. Please see my detailed comments below.
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Technical quality: whether experimental methods are appropriate, proofs are sound, results are well analyzed.</td><td style="width:80%;">
                            1-Low or very low
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Novelty/originality: in any aspect of the work, theory, algorithm, applications, experimental.</td><td style="width:80%;">
                            4-Oral level (significantly novel and impressive)
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Potential impact or usefulness: could be 
societal, academic, or practical and should be lasting in time, 
affecting a large number of people and/or bridge the gap between 
multiple disciplines.</td><td style="width:80%;">
                            3-Poster level (looks promising)
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Clarity and presentation: explanations, language and grammar, figures, graphs, tables, proper references.</td><td style="width:80%;">
                            2-Sub-standard for NIPS
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Qualitative assessment: Provide constructive 
feedback to the authors; justify and complement your ratings above. This
 is our MOST IMPORTANT QUESTION, we need to get good arguments for our 
decisions!</td><td style="width:80%;">
                            Summary:<br>This paper proposes a new 
approach to carrying out mini-batch based acceptance test for MCMC. It 
introduces a novel and interesting idea of absorbing the noise of the 
log-probability ratio estimate by decomposing the random variable X into
 a normal distribution and a correction term. Unfortunately, the 
proposed acceptance function mixes slower than the Metropolis acceptance
 function, the theoretical contribution is not rigorously proved, and 
the experiments do not show convincing evidence that the proposed 
algorithm is better than the adaptive M-H test.<br><br>Qualitative assessment:<br>This
 paper proposes a novel approach of conducting M-H test based on a 
mini-batch. I really like the idea of decomposing the distribution of 
the random X and use the normal part to absorb the error in the 
estimation of the log-probability ratio. This idea is quite original and
 could make a good impact if properly adopted. Unfortunately, this paper
 does not convert this idea into a practical algorithm. The algorithm 
design, theoretical analysis and empirical evaluations are problematic.<br><br>This
 paper first proposes a different acceptance function from the 
Metropolis function. The proposed M-H test with the logistic function is
 actually the Barker algorithm, first introduced in (Barker, 1965). I 
understand that the authors choose the logistic distribution in order to
 get a symmetric random distribution, but the Barker function is less 
efficient than the original Metropolis-Hastings algorithm. E.g., when 
the proposed location \theta is as good as \theta, M-H accepts it with a
 probability 1 but the Barker function has rejects it with a probability
 of 0.5.<br><br>Problem with the decomposition of X:<br>There is not an 
accurate definition of X_{norm} and X_{corr}. There are infinitely many 
ways to decompose X in Equation 6. Its not clearly what it means by If
 X_{norm} is exact in line 136. Although we do not instantiate X_{norm}
 in the algorithm, in the theoretical analysis in Sec 4, we need to a 
constructive definition for X_{norm} and X_{core} in order to study 
their property. E.g. in line 179, when we define X_{\xi}, how do we 
compute X_{norm} in the first hand?<br><br>The theoretical analysis of Sec 4 is not rigorous.<br>- In Lemma 2, central limit theorem applies for sufficiently large N and n and n &lt;&lt; N.<br>-
 In the proof of Lemma 3 and 4, we should use the mean value theorem to 
prove the first inequality in each proof rather than the Taylor 
expansion (high order term is not guaranteed to be smaller in all 
cases).<br>- The upper bound in Lemma 3 should be $2 \zeta l$ rather 
than $2 \zeta l$ because the total variation distance is 0.5 * l_1 
distance.<br>- Line 197, the maximum value of X_{\xi} is unbounded if 
distributed as Gaussian. Also, by definition, the variance of X_{\xi} is
 not necessarily smaller than \epsilon.<br>- What conclusion can get 
draw from Theorem 1? Is it possible for the difference of the 
approximate Markov chain from the exact posterior to diverge?<br>- The 
analysis of the approximation Markov chain does not consider the case 
when the estimated standard deviation exceeds 1.2. Simply skipping the 
iteration will break the detailed balance.<br><br>Problems with the experiment setting:<br>First
 of all, I do not agree that increasing the temperature is the correct 
way of satisfying the variance precondition. We should not avoid a 
weakness of an algorithm by changing the original problem we want to 
solve. Reducing the step size of the proposal distribution is a more 
reasonable choice.<br><br>Second, could the author explain how to choose
 the hyper-parameters of the mini-batch algorithm and the adaptive test 
in the experiment?<br><br>In experiment 5.1, it is hard to tell if the 
proposed method is better than the adaptive algorithm. Please show the 
two figures in Fig. 3 both in log-count or linear count for a fair 
comparison. Does the proposed algorithm include the K mini batches that 
are used to estimate std at every iteration into the count? I think the 
best way to compare the two algorithm is to estimate the effective 
sample size of each algorithm as a function of the number of processed 
data or running time, while the bias of the approximate distribution is 
controlled at the same level. <br><br>In experiment 5.2, according to 
the appendix, the proposed algorithm draws samples in the distribution 
with temperature = 3000 while the adaptive MH algorithm runs in the 
original distribution. We should not compare the accuracy or 
log-likelihood of two algorithms in two different posterior 
distributions.<br><br>In experiment 5.3, dropout is usually used for 
deep models during training but not used in the test phase. It is hard 
to provide a Bayesian explanation for dropout in this Bayesian NN 
problem. Also, the proposed algorithm does not help improve the 
log-likelihood.<br><br>Reference:<br>Barker, A.A.: Monte Carlo calculations of the radial distribution functions for a proton-electron<br>plasma. Australian Journal of Physics 18, 119133 (1965)<br>
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Reviewer confidence regarding this review.</td><td style="width:80%;">
                            3-Expert (read the paper in detail, know the area, quite certain of my opinion)
                        </td>
			</tr>
		</tbody></table>
	</div>
            
        
            <hr>
            <table>
                <tbody><tr>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl03_Label2" style="font-size:Small;font-weight:bold;">Masked Reviewer ID:</span>
                    </td>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl03_Label1" style="font-size:Small;">Assigned_Reviewer_4</span>
                    </td>
                </tr>
                <tr>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl03_Label3" style="font-size:Small;font-weight:bold;">Review:</span>
                    </td>
                    <td>
                    </td>
                </tr>
            </tbody></table>
            <div>
		<table rules="all" style="color:#333333;border-width:1px;border-style:None;font-family:Verdana;font-size:Small;border-collapse:collapse;" border="1" cellpadding="4" cellspacing="0">
			<tbody><tr style="color:White;background-color:#5D7B9D;font-weight:bold;">
				<th scope="col">Question</th><th scope="col">&nbsp;</th>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Summary: Provide a brief summary of the contents of the paper.</td><td style="width:80%;">
                            The article proposes a mini-batch acceptance
 test for Markov Chain Monte Carlo algorithm. Compared to Balan et al. 
(2014), the proposed algorithm uses a fixed mini-batch size instead of 
an adaptive one. The author illustrated the performance via several 
examples.
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Fatal flaws: Does the paper have a "fatal 
flaw" making it unfit for publication, regardless of other criteria (may
 include out of scope, double publication, plagiarism, wrong proofs, 
flawed experiments)? Use the text box to justify your answer.</td><td style="width:80%;">
                            No (not as far as I can see)
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Technical quality: whether experimental methods are appropriate, proofs are sound, results are well analyzed.</td><td style="width:80%;">
                            2-Sub-standard for NIPS
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Novelty/originality: in any aspect of the work, theory, algorithm, applications, experimental.</td><td style="width:80%;">
                            2-Sub-standard for NIPS
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Potential impact or usefulness: could be 
societal, academic, or practical and should be lasting in time, 
affecting a large number of people and/or bridge the gap between 
multiple disciplines.</td><td style="width:80%;">
                            2-Sub-standard for NIPS
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Clarity and presentation: explanations, language and grammar, figures, graphs, tables, proper references.</td><td style="width:80%;">
                            3-Poster level (good enough)
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Qualitative assessment: Provide constructive 
feedback to the authors; justify and complement your ratings above. This
 is our MOST IMPORTANT QUESTION, we need to get good arguments for our 
decisions!</td><td style="width:80%;">
                            First, the discussion of using the logistic 
acceptance function in Page 3 seems quite off topic. With the original 
MH test, the acceptance rule still takes the form of $\Delta &gt; \log 
u$ where u ~ uniform(0, 1). The logistic acceptance function actually 
has a uniformly lower acceptance rate than the original MH test. Correct
 me if I was wrong, but I don't see the advantage of using logistic 
acceptance test here.<br><br>Second, the central limit theorem only 
guarantee $\sqrt{N} \sum_i \log p(x_i|\theta)$ converge to Gaussian. It 
does not guarantee $N \sum_i \log p(x_i|\theta)$ converge to any 
distribution. Also I didn't quite get the argument in the whole Line 131
 - 154.<br><br>Third, the theoretical analysis is mostly within the 
framework of Balan et al. (2014), i.e., the original MCMC has to be 
uniformly ergodic and so on. However, the conditions are kind of weird. 
For example, for Lemma 3, it requires the estimator X_\xi to be 
uniformly bounded, which is almost impossible for distributions with 
unbounded support. In addition, the requirement on the bounded jumping 
step is also weird. It is almost impossible to control the jumping step 
in the actual implementation. Thus, the analysis is not very convincing.<br><br>
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Reviewer confidence regarding this review.</td><td style="width:80%;">
                            2-Confident (read it all; understood it all reasonably well)
                        </td>
			</tr>
		</tbody></table>
	</div>
            
        
            <hr>
            <table>
                <tbody><tr>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl04_Label2" style="font-size:Small;font-weight:bold;">Masked Reviewer ID:</span>
                    </td>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl04_Label1" style="font-size:Small;">Assigned_Reviewer_6</span>
                    </td>
                </tr>
                <tr>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl04_Label3" style="font-size:Small;font-weight:bold;">Review:</span>
                    </td>
                    <td>
                    </td>
                </tr>
            </tbody></table>
            <div>
		<table rules="all" style="color:#333333;border-width:1px;border-style:None;font-family:Verdana;font-size:Small;border-collapse:collapse;" border="1" cellpadding="4" cellspacing="0">
			<tbody><tr style="color:White;background-color:#5D7B9D;font-weight:bold;">
				<th scope="col">Question</th><th scope="col">&nbsp;</th>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Summary: Provide a brief summary of the contents of the paper.</td><td style="width:80%;">
                            In MCMC methods, the acceptance test 
requires computing the likelihood of all instances in the training set. 
In this paper, the authors present a method for approximating the 
acceptance probability using a small number of subsets of the training 
data sampled at random (minibatches). They present theoretical 
guarantees on convergence of the new method and empirically demonstrate 
significantly improved mixing times as a function of the computation 
time.
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Fatal flaws: Does the paper have a "fatal 
flaw" making it unfit for publication, regardless of other criteria (may
 include out of scope, double publication, plagiarism, wrong proofs, 
flawed experiments)? Use the text box to justify your answer.</td><td style="width:80%;">
                            No (not as far as I can see)
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Technical quality: whether experimental methods are appropriate, proofs are sound, results are well analyzed.</td><td style="width:80%;">
                            4-Oral level (top 3% submissions)
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Novelty/originality: in any aspect of the work, theory, algorithm, applications, experimental.</td><td style="width:80%;">
                            3-Poster level (some notable novel contributions)
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Potential impact or usefulness: could be 
societal, academic, or practical and should be lasting in time, 
affecting a large number of people and/or bridge the gap between 
multiple disciplines.</td><td style="width:80%;">
                            4-Oral level (many people will pick this up)
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Clarity and presentation: explanations, language and grammar, figures, graphs, tables, proper references.</td><td style="width:80%;">
                            4-Oral level (excellent in every respect)
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Qualitative assessment: Provide constructive 
feedback to the authors; justify and complement your ratings above. This
 is our MOST IMPORTANT QUESTION, we need to get good arguments for our 
decisions!</td><td style="width:80%;">
                            Good potential for impact. There seems to be
 significant interest in this problem, and the authors' model seems very
 easy to deploy in practice, while providing good theoretical guarantees
 on performance with only a reasonable set of basic assumptions. The 
authors compare with a good selection of current approaches to this 
problem and demonstrate significant advantages to their model.<br><br>The
 authors also  do a good job identifying and justifying the important 
motivating rationale behind their design and addressing potential 
drawbacks/considerations for their method.<br><br>Overall, I think this paper is well positioned, easily digestible, and has good potential for impact.
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Reviewer confidence regarding this review.</td><td style="width:80%;">
                            2-Confident (read it all; understood it all reasonably well)
                        </td>
			</tr>
		</tbody></table>
	</div>
            
        
            <hr>
            <table>
                <tbody><tr>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl05_Label2" style="font-size:Small;font-weight:bold;">Masked Reviewer ID:</span>
                    </td>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl05_Label1" style="font-size:Small;">Assigned_Reviewer_7</span>
                    </td>
                </tr>
                <tr>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl05_Label3" style="font-size:Small;font-weight:bold;">Review:</span>
                    </td>
                    <td>
                    </td>
                </tr>
            </tbody></table>
            <div>
		<table rules="all" style="color:#333333;border-width:1px;border-style:None;font-family:Verdana;font-size:Small;border-collapse:collapse;" border="1" cellpadding="4" cellspacing="0">
			<tbody><tr style="color:White;background-color:#5D7B9D;font-weight:bold;">
				<th scope="col">Question</th><th scope="col">&nbsp;</th>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Summary: Provide a brief summary of the contents of the paper.</td><td style="width:80%;">
                            The paper propose a novel approach to 
perform Metropolis-Hastings step in Markov Chain Monte Carlo efficiently
 using a subset of data.<br><br>Compared with prior work like [Balan et al 2014], it provide a more elaborate strategy. <br><br>Theoretical results are satisfactory.<br><br><br><br>
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Fatal flaws: Does the paper have a "fatal 
flaw" making it unfit for publication, regardless of other criteria (may
 include out of scope, double publication, plagiarism, wrong proofs, 
flawed experiments)? Use the text box to justify your answer.</td><td style="width:80%;">
                            Yes
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Explain fatal flaws if you ticked yes in the previous question.</td><td style="width:80%;">
                            The author mentions that in this method the size of mini-batch is fixed. <br><br>However, in Section 3.3, in Variance Preconditioning , the author mentions that "(b) increase the minibatch", contradict?
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Technical quality: whether experimental methods are appropriate, proofs are sound, results are well analyzed.</td><td style="width:80%;">
                            2-Sub-standard for NIPS
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Novelty/originality: in any aspect of the work, theory, algorithm, applications, experimental.</td><td style="width:80%;">
                            2-Sub-standard for NIPS
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Potential impact or usefulness: could be 
societal, academic, or practical and should be lasting in time, 
affecting a large number of people and/or bridge the gap between 
multiple disciplines.</td><td style="width:80%;">
                            2-Sub-standard for NIPS
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Clarity and presentation: explanations, language and grammar, figures, graphs, tables, proper references.</td><td style="width:80%;">
                            4-Oral level (excellent in every respect)
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Qualitative assessment: Provide constructive 
feedback to the authors; justify and complement your ratings above. This
 is our MOST IMPORTANT QUESTION, we need to get good arguments for our 
decisions!</td><td style="width:80%;">
                            This paper develop an alternative minibatch 
acceptance test for MH step in MCMC method which uses only a  subset of 
data.<br><br>It is easy to follow and theoretical analysis is thorough.<br><br>However,
 it seems that in variance preconditioning, size of minibatch is not 
fixed, contradicting with the statement in Introduction.<br><br>Moreover,
 the authors claim that this method works better than other method under
 GPU but does not support their view in experiment.<br><br>Furthermore, in NN experiment, why not compare the proposed method with conventional MH method ?<br>Why adaptive gradient descent method is chosen as baseline method instead of SGD ? <br>The size of dataset also seems limited. <br>It
 would be more convincing if the author can compare this method with 
adaptive MH [Balan et al 2014] in more high-dimensional large-scale 
dataset. 
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Reviewer confidence regarding this review.</td><td style="width:80%;">
                            3-Expert (read the paper in detail, know the area, quite certain of my opinion)
                        </td>
			</tr>
		</tbody></table>
	</div>
            
        
    <br>
    <br>

</div>
</td><td class="contentBorder">&nbsp;</td></tr></tbody></table>
</form>


</body></html>