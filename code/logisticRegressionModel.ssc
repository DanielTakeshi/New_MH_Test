:load simulator.ssc
:load cutMHTest.ssc
:load adaptiveMHTest.ssc

/**
 * Code for running Logistic Regression results. Documentation in progress (sorry).
 *
 * NOTE ON USAGE: this will run *one* of the three methods: ours, kora (Korattikara), and bard
 * (Bardenet). It used to run all three at once but I was getting out of memory errors when I did
 * that for larger datasets. The datasets here are fixed ahead of time in 'train_data_dir' and
 * 'test_data_dir' so the methods are going to be using the same data.
 * 
 * Fix the values in the parameters (listed at the start of this script) and run it using:
 *
 * [path_to_bidmach]./bidmach logisticRegressionModel.ssc | tee output.txt
 *
 * The output.txt should ideally be named something informative. Note that this script *needs the
 * other .ssc methods and other files* that are in this 'code' directory.
 */

// -------------------------------- //
// PARAMETERS and PRE-LOADING STUFF //
// -------------------------------- //

// IMPORTANT STUFF! AT LEAST CHECK THESE EVERY TIME YOU RUN SOMETHING!
val nsamps = 3000           // The number of \theta values to sample (i.e., number of iterations).
val test_to_use = "kora"    // Three options: "ours", "kora", or "bard". Use one of these.
val k = 1929350              // k = (#training)+(#testing) points. This will change the output data names.
val n = 1736415       // The number of training points, should be 80% of k.
val temperature = n/100.0   // This was 1000.0 for the previous MNIST (not 8M) experiment.
val batchsize = 5           // I'm also experimenting with changing minibatch sizes.
val cutMHeps = 0.05          // Set this here (to keep all modifiable parameters here).
val adapt_gamma = 2.00      // The gamma value for the adaptive MH test.

// LESS IMPORTANT STUFF BELOW
val train_data_dir = "/home/xinleipan/data/FINAL_MNIST8M_TRAIN_1736415.fmat.lz4"
val test_data_dir = "/home/xinleipan/data/FINAL_MNIST8M_TEST_192935.fmat.lz4";

val sigma = 1.0
val pscale = 1.0
val sigma_proposer = 0.05;

// Create the different tests we will be using.
val newtest = new NewTest;
newtest.explin = false;
val cutMHtest = new cutMHTest;
val adaptiveMHtest = new adaptiveMHTest;
cutMHtest.N = n;
adaptiveMHtest.N = n;
adaptiveMHtest.gamma = adapt_gamma;
cutMHtest.eps = cutMHeps

/**
 * TODO document!
 */
class LogisticRegression(n:Int, sigma:Double, pscale: Double) extends MHmodel (1, n, sigma, pscale) {
	
    var sigma_proposer = 0.05;
    var temp = 1.0;
    val data = loadFMat(train_data_dir);

    /**
     * TODO document!
     */
    def initfn():Mat = {
        val parameter_dim = data.dims(0) - 1;
        val theta = drand(parameter_dim,1);
        theta;
    };

    /**
     * TODO document!
     */
    def proposalfn(theta:Mat):Mat = {
        theta + dnormrnd(0, sigma_proposer, theta.dims(0), 1);
    };
    
    /**
     * TODO document!
     */
    def evalfn(batch:Mat, theta:Mat):Mat = {
        val X = batch(0 until batch.dims(0)-1, ?)
        val Y = batch(batch.dims(0)-1,?)
        val z = Y dot (theta.t * X);
        val sig = 1/(1 + exp(-1.0 * z));
        val log_sig = ln(sig);
        val scale_and_temp = 1.0 * (n/temp);
        scale_and_temp * log_sig;
    };
}
	
/**
 * TODO document!
 */
def eval_cost(X:DMat, Y:DMat, theta:DMat): (DMat, DMat) = {
	val z = Y *@ (theta.t * X);
	val sig = 1.0/ (1.0 + exp(-1.0 * z));
	var accuracy = dzeros(sig.dims(0),1);
	var ll = dzeros(sig.dims(0),1);
	for(i<- 0 until sig.dims(0)){
		val temp = sig(i, ?);
		accuracy(i) = find(temp>0.5).dims(0) * 1.0 / temp.dims(1) * 1.0;
		ll(i) = sum(ln(temp)).dv * 1.0 / temp.dims(1) * 1.0;
	}
	return (accuracy, ll);
};

/**
 * This will run exactly one of the three experiments. Don't use all of them, because that runs out
 * of memory (i.e., RAM) on bitter.
 *
 * @param exp_type The String which represents which test. Options: "ours", "kora", and "bard".
 * @param nn The LogisticRegression model we are using.
 */
 
def run_experiment(exp_type:String, nn:LogisticRegression) = {

    // TEST #1: OUR METHOD ("ours")
    if (exp_type == "ours") {
        
        val (samples, mb_size, ll_train) = dosimm(mod=nn, test=newtest, size=batchsize, nsamps=nsamps, acc=0.05);

        val testdata = loadFMat(test_data_dir);
        val X = testdata(0 until testdata.dims(0)-1, ?);
        var Y = testdata(testdata.dims(0)-1, ?);

        val (accuracy, ll_test) = eval_cost(X, Y, samples);
        val cum_size = cumsum(DMat(mb_size));

        saveAs("logistic_results_" +exp_type+ "_" +k+ ".mat", samples,       "samples_ours", 
                                                              cum_size,      "cum_size_ours",
                                                              DMat(mb_size), "mb_size_ours",
                                                              ll_train,      "ll_train_ours", 
                                                              ll_test,       "ll_test_ours", 
                                                              accuracy,      "accuracy_ours");
    }
    // TEST #2: KORATTIKARA ("kora")
    else if (exp_type == "kora") {
        val (samples, mb_size, ll_train) = cutMHTest_dosimm(mod=nn, test=cutMHtest, size=batchsize, nsamps=nsamps, acc=0.05);

        val testdata = loadFMat(test_data_dir);
        val X = testdata(0 until testdata.dims(0)-1, ?);
        var Y = testdata(testdata.dims(0)-1, ?);

        val (accuracy, ll_test) = eval_cost(X, Y, samples);
        val cum_size = cumsum(DMat(mb_size));

        saveAs("logistic_results_" +exp_type+ "_" +k+ ".mat", samples,       "samples_kora", 
                                                              cum_size,      "cum_size_kora",
                                                              DMat(mb_size), "mb_size_kora",
                                                              ll_train,      "ll_train_kora", 
                                                              ll_test,       "ll_test_kora", 
                                                              accuracy,      "accuracy_kora");
    }
    // TEST #3: BARDENET ("bard")
    else if (exp_type == "bard") {
        val (samples, mb_size, ll_train, bc1c2_list) = adaptiveMH_dosimm(mod=nn, test=adaptiveMHtest, size=batchsize, nsamps=nsamps, acc=0.05);

        val testdata = loadFMat(test_data_dir);
        val X = testdata(0 until testdata.dims(0)-1, ?);
        var Y = testdata(testdata.dims(0)-1, ?);

        val (accuracy, ll_test) = eval_cost(X, Y, samples);
        val cum_size = cumsum(DMat(mb_size));

        saveAs("logistic_results_" +exp_type+ "_" +k+ ".mat", samples,       "samples_bard", 
                                                              cum_size,      "cum_size_bard",
                                                              DMat(mb_size), "mb_size_bard",
                                                              ll_train,      "ll_train_bard", 
                                                              ll_test,       "ll_test_bard", 
                                                              accuracy,      "accuracy_bard");
    }
    else {
        println("Error, type=" +exp_type+ " not a valid type.")
        sys.exit
    }
}


// Define the Logistic Regression Model (we have to do it here after the class definition).
val nn = new LogisticRegression(n=n, sigma=sigma, pscale=pscale);
nn.temp = temperature;
nn.sigma_proposer = sigma_proposer;


// -------------------------- //
// CHOOSE WHICH METHOD TO RUN //
// -------------------------- //
val test_to_use = "ours"
run_experiment(test_to_use, nn)
val test_to_use = "kora"
run_experiment(test_to_use, nn)  
// val test_to_use = "bard"
// run_experiment(test_to_use, nn) 
