/**
 * Code for running Logistic Regression results.
 *
 * TODO Documentation in progress
 * TODO There needs to be a better way to input the data than what we have now.
 * TODO don't forget to adjust model parameters in case we change 'n'.
 */

// -------------------- //
// IMPORTANT PARAMETERS //
// -------------------- //

// Daniel: this should be 5000 but I may change if I'm experimenting.
val nsamps = 5000 

// This was 12007 for regular MNIST. **If changing, this automatically changes the data directories!**
val n = 1000
// val train_data_dir = "/home/seita/BIDMach/data/MNIST8M_daniel/FINAL_MNIST8M_TRAIN_" +n+ ".fmat.lz4"
// val test_data_dir = "/home/seita/BIDMach/data/MNIST8M_daniel/FINAL_MNIST8M_TEST_" +n+ ".fmat.lz4"

val train_data_dir = "/users/xinleipan/git/New_MH_Test/data/FINAL_MNIST8M_TRAIN_" + n + ".fmat.lz4"
val test_data_dir = "/users/xinleipan/git/New_MH_Test/data/FINAL_MNIST8M_TEST_" + n + ".fmat.lz4"

val sigma = 1.0
val pscale = 1.0
val batchsize = 100
val sigma_proposer = 0.05;
val temperature = 1000.0 // Was 1000.0 for regular MNIST experiment.



:load simulator.ssc
:load cutMHTest.ssc
:load adaptiveMHTest.ssc

class LogisticRegression(n:Int, sigma:Double, pscale: Double) extends MHmodel (1, n, sigma, pscale) {
	
    var sigma_proposer = 0.05;
    var temp = 1.0;
    // val data:DMat = load("minist7vs1.mat","Train");
    var data_loaded = loadFMat(train_data_dir);
    data_loaded(0 until data_loaded.dims(0)-1, ?) = data_loaded(0 until data_loaded.dims(0)-1, ?)/255.0;
    var labels = data_loaded(data_loaded.dims(0) -1, ?);
    labels(find(labels==7)) = -1;
    data_loaded(data_loaded.dims(0)-1,?) = labels;
    val data = data_loaded;
   
    def initfn():Mat = {
        val parameter_dim = data.dims(0) - 1;
        val theta = drand(parameter_dim,1);
        theta;
    };
    
    def proposalfn(theta:Mat):Mat = {
        theta + dnormrnd(0, sigma_proposer, theta.dims(0), 1);
    };
    
    def evalfn(batch:Mat, theta:Mat):Mat = {
        val X = batch(0 until batch.dims(0)-1, ?)
        val Y = batch(batch.dims(0)-1,?)
        val z = Y dot (theta.t * X);
        val sig = 1/(1 + exp(-1.0 * z));
        val log_sig = ln(sig);
        val scale_and_temp = 1.0 * (n/temp);
        scale_and_temp * log_sig;
    };
}
	
def eval_cost(X:DMat, Y:DMat, theta:DMat): (DMat, DMat) = {
	val z = Y *@ (theta.t * X);
	val sig = 1.0/ (1.0 + exp(-1.0 * z));
	var accuracy = dzeros(sig.dims(0),1);
	var ll = dzeros(sig.dims(0),1);
	for(i<- 0 until sig.dims(0)){
		val temp = sig(i, ?);
		accuracy(i) = find(temp>0.5).dims(0) * 1.0 / temp.dims(1) * 1.0;
		ll(i) = sum(ln(temp)).dv * 1.0 / temp.dims(1) * 1.0;
	}
	return (accuracy, ll);
};


// Define the Logistic Regression Model.
val nn = new LogisticRegression(n=n, sigma=sigma, pscale=pscale);
nn.temp = temperature;
nn.sigma_proposer = sigma_proposer;

// Create the differnet tests we will be using.
val newtest = new NewTest;
newtest.explin = false;
val oldtest = new OldTest;
oldtest.explin = false;
val cutMHtest = new cutMHTest;
val adaptiveMHtest = new adaptiveMHTest;
cutMHtest.N = n;
adaptiveMHtest.N = n;
cutMHtest.eps = 0.005;


// ---------------------------------------- //
// ----- TEST #1: OUR METHOD ("ours") ----- //
// ---------------------------------------- //
tic;
val (samples_ours, mb_size_ours, ll_train_ours) = dosimm(mod=nn, test=newtest, size=batchsize, nsamps=nsamps, acc=0.05);
val t1 = toc;

// ----------------------------------------- //
// ----- TEST #2: KORATTIKARA ("kora") ----- //
// ----------------------------------------- //
// val (samples_kora, mb_size_kora, ll_train_kora) = cutMHTest_dosimm(mod=nn, test=cutMHtest, size=batchsize, nsamps=nsamps, acc=0.05);
// val t2 = toc - t1;

// -------------------------------------- //
// ----- TEST #3: BARDENET ("bard") ----- //
// -------------------------------------- //
// val (samples_bard, mb_size_bard, ll_train_bard, bc1c2_list) = adaptiveMH_dosimm(mod=nn, test=adaptiveMHtest, size=batchsize, nsamps=nsamps, acc=0.05);
// val t3 = toc - t2;


// val testdata:DMat = load("minist7vs1.mat","Test");
val testdata = loadFMat(test_data_dir);
val X = testdata(0 until testdata.dims(0)-1, ?)/255.0;
var Y = testdata(testdata.dims(0)-1, ?);
Y(find(Y==7)) = -1;


// We will report on accuracy and (test) ll in the paper.
val (accuracy_ours, ll_test_ours) = eval_cost(X, Y, samples_ours);
// val (accuracy_kora, ll_test_kora) = eval_cost(X, Y, samples_kora);
// val (accuracy_bard, ll_test_bard) = eval_cost(X, Y, samples_bard);

// Cumulative sizes, for showing efficiency.
val cum_size_ours = cumsum(DMat(mb_size_ours));
// val cum_size_kora = cumsum(DMat(mb_size_kora));
// val cum_size_bard = cumsum(DMat(mb_size_bard));

// Might be useful later.
// val times = t1 \ t2 \ t3
// print(times)

// Save all this for analysis later in jupyter notebook.
/* saveAs("logisticdata.mat", samples_ours, "samples_ours", 
                           samples_kora, "samples_kora",
                           samples_bard, "samples_bard",
                           cum_size_ours, "cum_size_ours",
                           cum_size_kora, "cum_size_kora", 
                           cum_size_bard, "cum_size_bard",
                           DMat(mb_size_ours), "mb_size_ours",
                           DMat(mb_size_kora), "mb_size_kora",
                           DMat(mb_size_bard), "mb_size_bard",
                           ll_train_ours, "ll_train_ours", 
                           ll_train_kora, "ll_train_kora", 
                           ll_train_bard, "ll_train_bard", 
                           ll_test_ours, "ll_test_ours", 
                           ll_test_kora, "ll_test_kora", 
                           ll_test_bard, "ll_test_bard", 
                           accuracy_ours, "accuracy_ours", 
                           accuracy_kora, "accuracy_kora", 
                           accuracy_bard, "accuracy_bard");
*/
