:load simulator.ssc
:load cutMHTest.ssc
:load adaptiveMHTest.ssc

/**
 * Code for running Logistic Regression results.
 *
 * TODO Documentation in progress
 * TODO There needs to be a better way to input the data than what we have now.
 * TODO don't forget to adjust model parameters in case we change 'n'.
 * NOTE ON USAGE: Go to the bottom of the script to choose which method you want to run. You can
 * only run one of the three at a time (this helps to save memory) but the data should be the same
 * as they are pre-generated ahead of time.
 */

// -------------------------------- //
// PARAMETERS and PRE-LOADING STUFF //
// -------------------------------- //

// Daniel: this should be 5000 but I may change if I'm experimenting.
val nsamps = 3000 

// IMPORTANT! Options: "ours", "kora", or "bard".
val test_to_use = "bard"

// This was 12007 for regular MNIST. **If changing, this automatically changes the data
// directories!** As well as the output matrix that we save.
val k = 20000
val n = (0.8*k).toInt     // The number of training points, should be 80% of k . (k = training + testing)
val train_data_dir = "/home/seita/BIDMach/data/MNIST8M_daniel/FINAL_MNIST8M_TRAIN_" +k+ ".fmat.lz4"
val test_data_dir = "/home/seita/BIDMach/data/MNIST8M_daniel/FINAL_MNIST8M_TEST_" +k+ ".fmat.lz4"

val sigma = 1.0
val pscale = 1.0
val batchsize = 100
val sigma_proposer = 0.05;
val temperature = 200.0 // Was 1000.0 for previous MNIST experiment.

// Let's load the test data.
val testdata = loadFMat(test_data_dir);
val X = testdata(0 until testdata.dims(0)-1, ?)/255.0;
var Y = testdata(testdata.dims(0)-1, ?);
Y(find(Y==7)) = -1;

// Create the different tests we will be using.
val newtest = new NewTest;
newtest.explin = false;
val oldtest = new OldTest;
oldtest.explin = false;
val cutMHtest = new cutMHTest;
val adaptiveMHtest = new adaptiveMHTest;
cutMHtest.N = n;
adaptiveMHtest.N = n;
cutMHtest.eps = 0.005;

/**
 * TODO document!
 */
class LogisticRegression(n:Int, sigma:Double, pscale: Double) extends MHmodel (1, n, sigma, pscale) {
	
    var sigma_proposer = 0.05;
    var temp = 1.0;
    var data_loaded = loadFMat(train_data_dir);
    data_loaded(0 until data_loaded.dims(0)-1, ?) = data_loaded(0 until data_loaded.dims(0)-1, ?)/255.0;
    var labels = data_loaded(data_loaded.dims(0)-1, ?);
    labels(find(labels==7)) = -1;
    data_loaded(data_loaded.dims(0)-1,?) = labels;
    val data = data_loaded;

    /**
     * TODO document!
     */
    def initfn():Mat = {
        val parameter_dim = data.dims(0) - 1;
        val theta = drand(parameter_dim,1);
        theta;
    };

    /**
     * TODO document!
     */
    def proposalfn(theta:Mat):Mat = {
        theta + dnormrnd(0, sigma_proposer, theta.dims(0), 1);
    };
    
    /**
     * TODO document!
     */
    def evalfn(batch:Mat, theta:Mat):Mat = {
        val X = batch(0 until batch.dims(0)-1, ?)
        val Y = batch(batch.dims(0)-1,?)
        val z = Y dot (theta.t * X);
        val sig = 1/(1 + exp(-1.0 * z));
        val log_sig = ln(sig);
        val scale_and_temp = 1.0 * (n/temp);
        scale_and_temp * log_sig;
    };
}
	
/**
 * TODO document!
 */
def eval_cost(X:DMat, Y:DMat, theta:DMat): (DMat, DMat) = {
	val z = Y *@ (theta.t * X);
	val sig = 1.0/ (1.0 + exp(-1.0 * z));
	var accuracy = dzeros(sig.dims(0),1);
	var ll = dzeros(sig.dims(0),1);
	for(i<- 0 until sig.dims(0)){
		val temp = sig(i, ?);
		accuracy(i) = find(temp>0.5).dims(0) * 1.0 / temp.dims(1) * 1.0;
		ll(i) = sum(ln(temp)).dv * 1.0 / temp.dims(1) * 1.0;
	}
	return (accuracy, ll);
};

/**
 * This will run exactly one of the three experiments. Don't use all of them, because that runs out
 * of memory (i.e., RAM) on bitter.
 *
 * @param exp_type The String which represents which test. Options: "ours", "kora", and "bard".
 * @param nn The LogisticRegression model we are using.
 */
def run_experiment(exp_type:String, nn:LogisticRegression) = {

    // TEST #1: OUR METHOD ("ours")
    if (exp_type == "ours") {
        val (samples, mb_size, ll_train) = dosimm(mod=nn, test=newtest, size=batchsize, nsamps=nsamps, acc=0.05);
        val (accuracy, ll_test) = eval_cost(X, Y, samples);
        val cum_size = cumsum(DMat(mb_size));

        saveAs("logistic_results_" +exp_type+ "_" +k+ ".mat", samples,       "samples_ours", 
                                                              cum_size,      "cum_size_ours",
                                                              DMat(mb_size), "mb_size_ours",
                                                              ll_train,      "ll_train_ours", 
                                                              ll_test,       "ll_test_ours", 
                                                              accuracy,      "accuracy_ours");
    }
    // TEST #2: KORATTIKARA ("kora")
    else if (exp_type == "kora") {
        val (samples, mb_size, ll_train) = cutMHTest_dosimm(mod=nn, test=cutMHtest, size=batchsize, nsamps=nsamps, acc=0.05);
        val (accuracy, ll_test) = eval_cost(X, Y, samples);
        val cum_size = cumsum(DMat(mb_size));

        saveAs("logistic_results_" +exp_type+ "_" +k+ ".mat", samples,       "samples_kora", 
                                                              cum_size,      "cum_size_kora",
                                                              DMat(mb_size), "mb_size_kora",
                                                              ll_train,      "ll_train_kora", 
                                                              ll_test,       "ll_test_kora", 
                                                              accuracy,      "accuracy_kora");
    }
    // TEST #3: BARDENET ("bard")
    else if (exp_type == "bard") {
        val (samples, mb_size, ll_train, bc1c2_list) = adaptiveMH_dosimm(mod=nn, test=adaptiveMHtest, size=batchsize, nsamps=nsamps, acc=0.05);
        val (accuracy, ll_test) = eval_cost(X, Y, samples);
        val cum_size = cumsum(DMat(mb_size));

        saveAs("logistic_results_" +exp_type+ "_" +k+ ".mat", samples,       "samples_bard", 
                                                              cum_size,      "cum_size_bard",
                                                              DMat(mb_size), "mb_size_bard",
                                                              ll_train,      "ll_train_bard", 
                                                              ll_test,       "ll_test_bard", 
                                                              accuracy,      "accuracy_bard");
    }
    else {
        println("Error, type=" +exp_type+ " not a valid type.")
        sys.exit
    }
}


// Define the Logistic Regression Model (we have to do it here after the class definition).
val nn = new LogisticRegression(n=n, sigma=sigma, pscale=pscale);
nn.temp = temperature;
nn.sigma_proposer = sigma_proposer;

// -------------------------- //
// CHOOSE WHICH METHOD TO RUN //
// -------------------------- //
run_experiment(test_to_use, nn) 

