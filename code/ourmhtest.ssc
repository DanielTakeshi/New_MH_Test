// script to run our MH test on Gaussian Mixture Model
val n2lsigma = 1.0;
val nn2l = 2000;
val norm2logdata = loadDMat("norm2log%d_20_%2.1f.txt" format(nn2l, n2lsigma));
val n2ld = norm2logdata(?,0) \ cumsum(norm2logdata(?,1));

:silent
abstract class MHmodel(val ndim:Int, val n:Int, val sigma:Double, val pscale:Double) {
    val data:Mat;  // data set used to estimate posterior
    def initfn():Mat; // init parameter set
    def proposalfn(theta:Mat):Mat; // propose next parameter set
    def evalfn(batch:Mat,theta:Mat):Mat; // evaluate likelihood
};

abstract class MHtestType {
    def testfn(diff:Mat, logu:Double, nsig:Double):(Boolean, Boolean);
    val explin:Boolean;
    def discount(P:Double, n:Int):Double;    
    var keepon = true;
};

def normcdf(a:DMat):DMat = {
    0.5 + 0.5 * erf(a / math.sqrt(2));
};

def normcdfinv(a:DMat):DMat = {
    math.sqrt(2) * erfinv(2*a - 1);
};

def normlogrnd(m:Int, n:Int):DMat = {
    val rr = drand(m, n);
    var i = 0;
    while (i < rr.length) {
	val rv = rr.data(i);
	var top = n2ld.nrows;
	var bottom = 0;
	while (top - bottom > 1) {
	    val mid = (top + bottom) / 2;
	    if (rv > n2ld(mid, 1)) {
		bottom = mid;
	    } else {
		top = mid;
	    }
	}
	val y0 = n2ld(bottom, 1);
	val y1 = n2ld(math.min(top, n2ld.nrows-1), 1);
	val alpha = if (y1 != y0) ((rv - y0) / (y1 - y0)) else 0.0;
	val x0 = n2ld(bottom, 0);
	val x1 = n2ld(math.min(top, n2ld.nrows-1), 0);
	val newx = alpha * x1 + (1-alpha) * x0;
	rr.data(i) = newx;
	i += 1;
    }
    rr;
};

class NewTest extends MHtestType {
    def testfn(diff:Mat, logu:Double, nsig:Double):(Boolean, Boolean) = {
	val targvar = n2lsigma * n2lsigma;
	val tvar = variance(diff).dv/diff.length;
	val x = mean(diff).dv;
	val ns = x / math.sqrt(tvar);
	if (math.abs(ns) > 5) {
	    if (ns > 0) {
		(true, true);
	    } else {
		(true, false);
	    }
	} else {
	    if (tvar >= targvar) {
		if (nsig == 0) {
		    if (keepon) {
			println("Warning: New test failed variance condition, var=%f nstd = %f" format (tvar, ns));
			if (x > 0) {
			    (true, true);
			} else {
			    (true, false);
			}
		    } else {
			throw new RuntimeException("New test failed variance condition, var=%f, nstd = %f" format (tvar, ns));
		    }
		} else {
		    (false, false);
		}
	    } else {
		val xn = dnormrnd(0, math.sqrt(targvar - tvar), 1, 1).dv;
		val xc = normlogrnd(1,1).dv;
		if ((x + xn + xc) > 0) {
		    (true, true);
		} else {
		    (true, false);
		}
	    }
	}
    };
    val explin = true;
    def discount(p:Double, n:Int):Double = p;
};

class OldTest extends MHtestType {
    def testfn(diff:Mat, logu:Double, nsig:Double):(Boolean, Boolean) = {
	val tstd = math.sqrt(variance(diff).dv/diff.length);
	val ndiff = mean(diff - logu).dv / tstd;
	if (math.abs(ndiff) < nsig) {
	    (false, false);
	} else {
	    if (ndiff > 0) {
		(true, true);
	    } else {
		(true, false);
	    }
	}
    };
    val explin = true;
    def discount(p:Double, n:Int):Double = {
	val r = 0.5;
	p * (1 - r) * math.pow(r, n);
    }
};

def getbatch(data:Mat, here:Int, size:Int):Mat = {
    val there = here + size;
    val nthere = math.min(there, data.ncols);
    val iwrap = math.max(0, there - data.ncols);
    val batch0 = data.colslice(here, nthere, null);
    val batch = if (iwrap > 0) {
	batch0 \ data.colslice(0, iwrap, null);
    } else {
	batch0;
    }
    batch;
};    

def dostep(mod:MHmodel, test:MHtestType, data:Mat, size:Int, here:Int, theta:Mat, ttheta:Mat, acc:Double):(Int, Mat, Double) = {
    var step = size;
    var done = false;
    var ntheta:Mat = null;
    var there = 0;
    var logu = ln(rand(1,1)).v;
    var istep = 0;
    var ll:Mat = null;
    while (! done) {
	val batch = getbatch(mod.data, here, step);
	ll = mod.evalfn(batch, theta);
	val diff = mod.evalfn(batch, ttheta) - ll;
	val nsig = if (step == data.ncols) 0.0 else (- normcdfinv(drow(test.discount(acc, istep))).dv);	
	val (moved, takestep) = test.testfn(diff, logu, nsig);
	done = moved;
	if (done) {
	    there = (here + step) % data.ncols;
	    ntheta = if (takestep) ttheta else theta;
	} else {
	    step = math.min(if (test.explin) (step*2) else (step + size), data.ncols);
	}
	istep += 1;
    }
    (there, ntheta, mean(ll).dv);
};

def dosimm(mod:MHmodel, test:MHtestType, size:Int, nsamps:Int, acc:Double):(DMat,LMat,DMat) = {
    var theta = mod.initfn();
    hist(mod.data);
    val samples = dzeros(theta.length, nsamps);
    val sizes = lzeros(1, nsamps);
    val lls = dzeros(1, nsamps);
    var here = 0;
    var i = 0;
    while (i < nsamps) {
	println("iteration %d" format (i) );
	val ttheta = mod.proposalfn(theta);
	val (there, nth, ll) = dostep(mod, test, mod.data, size, here, theta, ttheta, acc);
	sizes(i) = if (there > here) (there - here) else (there - here + mod.data.ncols);
	lls(i) = ll;
	here = there;
	theta = nth;
	samples(?, i) = DMat(theta);
	i += 1;
    }
    (samples, sizes, lls);
};

class NormModel(ndim:Int, n:Int, sigma:Double, pscale:Double) extends MHmodel(ndim, n, sigma, pscale) {
    val data = dnormrnd(0, sigma, ndim, n);
    val sigmat = sigma/math.sqrt(n);
    val sigmap = sigmat*pscale/math.sqrt(ndim);
    var temp = 1.0;
    
    def initfn():Mat = {
	dnormrnd(0, sigmat * math.sqrt(temp), ndim, 1);
    };
    
    def proposalfn(theta:Mat):Mat = {
	theta + dnormrnd(0, sigmap * math.sqrt(temp), ndim, 1);
    };
    
    def evalfn(batch:Mat,theta:Mat):Mat = {
	val dd = batch - theta;
	-(n / (2 * sigma * sigma * temp)) * (dd dot dd);
    };
};


class GaussianMixture(ndim:Int, n:Int, sigma:Double, pscale:Double) extends MHmodel(ndim, n, sigma, pscale) {
	
	// ndim: dimension of data set. Should be 1
	// n:    number of data point in the data set
	// sigma:std of the data 
	
	// val sigmat = sigma/math.sqrt(n);
    	// val sigmap = sigmat*pscale/math.sqrt(ndim);

	val sigma1_sq = 10.0;	
	val sigma2_sq = 1.0;
	val sigma_proposer = 0.03;
	val theta1 = 0.0;
	val theta2 = 1.0;
	val u = rand(1,n);
	val data = dzeros(1,n);
	var temp = 1.0;

	def initfn():Mat = {
		// Data Generation
		for(i <- 0 until n){
			if (u(i) < 0.5){
				data(i) = dnormrnd(theta1, sigma.toFloat,1,1)(0)
			}
			else{
				data(i) = dnormrnd(theta1+theta2, sigma.toFloat,1,1)(0)
			}
		};
		
		// Initialize parameters
		val res = dones(2,1);
		res(0) = 0.5;
		res(1) = 0.0;
		res;
	};

	def proposalfn(theta:Mat):Mat ={
		theta +  dnormrnd(0, sigma_proposer, ndim, 1);
	};

	def evalfn(batch:Mat, theta:Mat) : Mat = {
		val dd1 = batch - theta(0);
		val dd2 = batch - theta(0) - theta(1);
		val scale_and_temp = 1.0 * (n/temp);
		val log_term = ln( exp( -0.5 / (sigma * sigma) * ( dd1 dot dd1) ) + exp( -0.5 / (sigma * sigma) * (dd2 dot dd2) ) );
		scale_and_temp * log_term;
	};

};


val nn = new GaussianMixture(ndim=1, n = 10000, sigma = math.sqrt(2), pscale=1);
nn.temp = 110.0;
val newtest = new NewTest;
val oldtest = new OldTest;

tic; 

// mod: model, test: testtype, size: minibatch size, nsamps = number of iteration, 

val (samples, sizes, lls) = dosimm(mod=nn, test=newtest, size=100, nsamps = 20000, acc = 0.05);
val t1 = toc;

val (samples2, sizes2, lls2) = dosimm(mod=nn, test=oldtest, size=100, nsamps = 20000, acc = 0.05);

val t2 = toc - t1;

val size1 = zeros(1,20000);
val size2 = zeros(1,20000);
for(i<- 0 until 20000){
	size1(i) = sizes(i)(0);
};

for(i<- 0 until 20000){
	size2(i) = sizes2(i)(0);
};

hist(size1);
hist(size2);
