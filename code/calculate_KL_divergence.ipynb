{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import *\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import t\n",
    "from bisect import bisect\n",
    "import scipy.io\n",
    "import copy\n",
    "from scipy.stats import norm\n",
    "from scipy.special import gamma\n",
    "import numpy.matlib\n",
    "%matplotlib inline\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cutting the MH budget method refers to Korattikara's 2014 paper\n",
    "\n",
    "Adaptive MH method refers to Bardenet's 2014 paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate some ground truth\n",
    "N = 1000000;\n",
    "sigma1_sq = 10\n",
    "sigma2_sq = 1\n",
    "sigmax_sq = 2\n",
    "theta1 = 0\n",
    "theta2 = 1\n",
    "\n",
    "# Generate the data matrix. Note that the np.random.normal(...) requires STD (not VAR).\n",
    "X = np.zeros(N)\n",
    "for i in xrange(N):\n",
    "    u = np.random.random()\n",
    "    if (u < 0.5):\n",
    "        X[i] = np.random.normal(theta1, np.sqrt(sigmax_sq))\n",
    "    else:\n",
    "        X[i] = np.random.normal(theta1+theta2, np.sqrt(sigmax_sq))\n",
    "\n",
    "\n",
    "def log_f(theta, X, N, T):\n",
    "    # the variance of X is 2, the variance of theta[0] is 10, the variance of theta[1] is 1\n",
    "    scale_and_temp = N / float(len(X) * T)\n",
    "    \n",
    "    inverse_covariance = np.array([[0.1,0],[0,1]])\n",
    "    prior_constant = 1.0 / (2*np.pi*np.sqrt(10))\n",
    "    prior = np.log(prior_constant) - 0.5*(theta.T).dot(inverse_covariance).dot(theta)\n",
    "    \n",
    "    X_all = X.reshape((len(X),1))\n",
    "    ll_constant = (1.0 / (4*np.sqrt(np.pi)))\n",
    "    L = ll_constant * (np.exp(-0.25*(X_all-theta[0])**2) + np.exp(-0.25*(X_all-(theta[0]+theta[1]))**2))\n",
    "    log_likelihood = np.sum(np.log(L)) * scale_and_temp\n",
    "    \n",
    "    assert (N / float(len(X))) >= 1\n",
    "    assert not np.isnan(prior + log_likelihood)\n",
    "    return (prior + log_likelihood)[0,0]\n",
    "\n",
    "\n",
    "def estimate_kl_divergence(all_thetas, d_space, full_data, temp=10000, contour=False):\n",
    "   \n",
    "    (m,n) = all_thetas.shape\n",
    "    assert m == 2\n",
    "    assert 0.001 <= d_space <= 1.0 \n",
    "    \n",
    "    # Let's deal with the grid limits and perform any necessary clipping of data.\n",
    "    (min_x, max_x) = (-1.5, 2.5)\n",
    "    (min_y, max_y) = (-2.5, 2.5)\n",
    "    clipped_thetas = np.zeros((m,n))\n",
    "    clipped_thetas[0] = np.maximum( np.minimum(all_thetas[0], max_x), min_x )\n",
    "    clipped_thetas[1] = np.maximum( np.minimum(all_thetas[1], max_y), min_y )\n",
    "    \n",
    "    # Round each element in clipped_thetas to its nearest multiple within d_space.\n",
    "    thetas_rounded = d_space * np.rint(clipped_thetas/d_space)\n",
    "    \n",
    "    # Form the grid of points. Add d_space because arange doesn't include the last element.\n",
    "    x_coords = np.arange(min_x, max_x + d_space, d_space)\n",
    "    y_coords = np.arange(min_y, max_y + d_space, d_space)\n",
    "    num_x = len(x_coords)\n",
    "    num_y = len(y_coords)\n",
    "    \n",
    "    # Deal with the source distribution (theoretical distribution), which calls our function. Exponentiate later.\n",
    "    source_distribution = np.zeros((num_x,num_y))\n",
    "    for xc in range(num_x):\n",
    "        for yc in range(num_y):\n",
    "            (theta1,theta2) = (x_coords[xc],y_coords[yc])\n",
    "            this_theta = np.array([[theta1],[theta2]])\n",
    "            source_distribution[xc,yc] = log_f(this_theta, full_data, len(full_data), temp)\n",
    "            assert not np.isnan(source_distribution[xc,yc])\n",
    "    source_distribution = np.exp(source_distribution)\n",
    "    \n",
    "    # Do the target distribution (actual data), iterating through theta_rounded. Do NOT exponentiate!\n",
    "    target_distribution = np.zeros((num_x,num_y))\n",
    "    for theta in thetas_rounded.T: \n",
    "        # Note the transpose above. Given theta, multiply by d_space to get integer coords.\n",
    "        (xt,yt) = np.rint(theta/d_space)\n",
    "        xt = int(xt)\n",
    "        yt = int(yt)\n",
    "        target_distribution[xt,yt] = target_distribution[xt,yt] + 1\n",
    "    \n",
    "    # Smooth the distributions by adding in a small constant, then normalize.\n",
    "    # eps = 0.0001\n",
    "    # source_distribution = source_distribution + eps\n",
    "    # target_distribution = target_distribution + eps\n",
    "    source_distribution = source_distribution / np.sum(source_distribution)\n",
    "    target_distribution = target_distribution / np.sum(target_distribution)\n",
    "    \n",
    "    source_distribution = np.rint(source_distribution * n)\n",
    "    target_distribution = np.rint(target_distribution * n)\n",
    "    # Finally, compute an estimate of the KL divergence.\n",
    "    kldiv = 0.0\n",
    "    for xc in range(num_x):\n",
    "        for yc in range(num_y):\n",
    "            p_xy = source_distribution[xc,yc]\n",
    "            q_xy = target_distribution[xc,yc]\n",
    "            if p_xy != 0.0 and q_xy!=0.0:\n",
    "                # kldiv += (p_xy)*(np.log(p_xy) - np.log(q_xy))\n",
    "                kldiv += q_xy * np.log(p_xy) *1.0 - p_xy *1.0 - np.log(gamma(q_xy+1))\n",
    "                assert not np.isnan(kldiv)\n",
    "        \n",
    "    # Return what we want all along.\n",
    "    return kldiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data finished!\n"
     ]
    }
   ],
   "source": [
    "# test parameters : with nsamps = 5000, minibatchsize = 100, sigma_proposer = 0.3\n",
    "# number of data points = 1000,000 temperature = 10,000\n",
    "'''load data '''\n",
    "f = h5py.File('gaussiandata.mat','r');\n",
    "samples1 = np.array(f['newtestsamples'])\n",
    "samples2 = np.array(f['oldtestsamples'])\n",
    "samples3 = np.array(f['cutmhsamples'])\n",
    "samples4 = np.array(f['adaptivemhsamples'])\n",
    "samples5 = np.array(f['cutmhwithsamples'])\n",
    "size1 = np.array(f['newtestsize'])\n",
    "size2 = np.array(f['oldtestsize'])\n",
    "size3 = np.array(f['cutmhsize'])\n",
    "size4 = np.array(f['adaptivemhsize'])\n",
    "size5 = np.array(f['cutmhwithsize'])\n",
    "ll1 = np.array(f['newtestll'])\n",
    "ll2 = np.array(f['oldtestll'])\n",
    "ll3 = np.array(f['cutmhll'])\n",
    "ll4 = np.array(f['adaptivemhll'])\n",
    "bc1c2 = np.array(f['adaptivemhbc1c2'])\n",
    "time_list = np.array(f['time_list'])\n",
    "print 'load data finished!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2153.68335108\n",
      "-2807.63634814\n",
      "-4008.39351288\n",
      "-2656.04723512\n",
      "-2039.17289303\n"
     ]
    }
   ],
   "source": [
    "# calculate kl divergence\n",
    "kl1 = estimate_kl_divergence(samples1.T, 0.1, X, 10000.0)\n",
    "print kl1\n",
    "kl2 = estimate_kl_divergence(samples2.T, 0.1, X, 10000.0)\n",
    "print kl2\n",
    "kl3 = estimate_kl_divergence(samples3.T, 0.1, X, 10000.0)\n",
    "print kl3\n",
    "kl4 = estimate_kl_divergence(samples4.T, 0.1, X, 10000.0)\n",
    "print kl4\n",
    "kl5 = estimate_kl_divergence(samples5.T, 0.1, X, 10000.0)\n",
    "print kl5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
