// script to run our MH test on Gaussian Mixture Model
val n2lsigma = 1.0;
val nn2l = 2000;
val norm2logdata = loadDMat("norm2log%d_20_%2.1f.txt" format(nn2l, n2lsigma));
val n2ld = norm2logdata(?,0) \ cumsum(norm2logdata(?,1));

:silent
abstract class MHmodel(val ndim:Int, val n:Int, val sigma:Double, val pscale:Double) {
    val data:Mat;  // data set used to estimate posterior
    def initfn():Mat; // init parameter set
    def proposalfn(theta:Mat):Mat; // propose next parameter set
    def evalfn(batch:Mat,theta:Mat):Mat; // evaluate likelihood
};

abstract class MHtestType {
    def testfn(diff:Mat, logu:Double, nsig:Double):(Boolean, Boolean);
    var explin:Boolean;
    def discount(P:Double, n:Int):Double;    
    var keepon = true;
};

def normcdf(a:DMat):DMat = {
    0.5 + 0.5 * erf(a / math.sqrt(2));
};

def normcdfinv(a:DMat):DMat = {
    math.sqrt(2) * erfinv(2*a - 1);
};

def normlogrnd(m:Int, n:Int):DMat = {
    val rr = drand(m, n);
    var i = 0;
    while (i < rr.length) {
	val rv = rr.data(i);
	var top = n2ld.nrows;
	var bottom = 0;
	while (top - bottom > 1) {
	    val mid = (top + bottom) / 2;
	    if (rv > n2ld(mid, 1)) {
		bottom = mid;
	    } else {
		top = mid;
	    }
	}
	val y0 = n2ld(bottom, 1);
	val y1 = n2ld(math.min(top, n2ld.nrows-1), 1);
	val alpha = if (y1 != y0) ((rv - y0) / (y1 - y0)) else 0.0;
	val x0 = n2ld(bottom, 0);
	val x1 = n2ld(math.min(top, n2ld.nrows-1), 0);
	val newx = alpha * x1 + (1-alpha) * x0;
	rr.data(i) = newx;
	i += 1;
    }
    rr;
};

class NewTest extends MHtestType {
    def testfn(diff:Mat, logu:Double, nsig:Double):(Boolean, Boolean) = {
	val targvar = n2lsigma * n2lsigma;
	val tvar = variance(diff).dv/diff.length;
	val x = mean(diff).dv;
	val ns = x / math.sqrt(tvar);
	if (math.abs(ns) > 5) {
	    if (ns > 0) {
		(true, true);
	    } else {
		(true, false);
	    }
	} else {
	    if (tvar >= targvar) {
		if (nsig == 0) {
		    if (keepon) {
			println("Warning: New test failed variance condition, var=%f nstd = %f" format (tvar, ns));
			if (x > 0) {
			    (true, true);
			} else {
			    (true, false);
			}
		    } else {
			throw new RuntimeException("New test failed variance condition, var=%f, nstd = %f" format (tvar, ns));
		    }
		} else {
		    (false, false);
		}
	    } else {
		val xn = dnormrnd(0, math.sqrt(targvar - tvar), 1, 1).dv;
		val xc = normlogrnd(1,1).dv;
		if ((x + xn + xc) > 0) {
		    (true, true);
		} else {
		    (true, false);
		}
	    }
	}
    };
    var explin = true;
    def discount(p:Double, n:Int):Double = p;
};

class OldTest extends MHtestType {
    def testfn(diff:Mat, logu:Double, nsig:Double):(Boolean, Boolean) = {
	val tstd = math.sqrt(variance(diff).dv/diff.length);
	val ndiff = mean(diff - logu).dv / tstd;
	if (math.abs(ndiff) < nsig) {
	    (false, false);
	} else {
	    if (ndiff > 0) {
		(true, true);
	    } else {
		(true, false);
	    }
	}
    };
    var explin = true;
    def discount(p:Double, n:Int):Double = {
	val r = 0.5;
	p * (1 - r) * math.pow(r, n);
    }
};

def getbatch(data:Mat, here:Int, size:Int):Mat = {
    val there = here + size;
    val nthere = math.min(there, data.ncols);
    val iwrap = math.max(0, there - data.ncols);
    val batch0 = data.colslice(here, nthere, null);
    val batch = if (iwrap > 0) {
	batch0 \ data.colslice(0, iwrap, null);
    } else {
	batch0;
    }
    batch;
};    

def dostep(mod:MHmodel, test:MHtestType, data:Mat, size:Int, here:Int, theta:Mat, ttheta:Mat, acc:Double):(Int, Mat, Double) = {
    var step = size;
    var done = false;
    var ntheta:Mat = null;
    var there = 0;
    var logu = ln(rand(1,1)).v;
    var istep = 0;
    var ll:Mat = null;
    while (! done) {
	val batch = getbatch(mod.data, here, step);
	ll = mod.evalfn(batch, theta);
	val diff = mod.evalfn(batch, ttheta) - ll;
	val nsig = if (step == data.ncols) 0.0 else (- normcdfinv(drow(test.discount(acc, istep))).dv);	
	val (moved, takestep) = test.testfn(diff, logu, nsig);
	done = moved;
	if (done) {
	    there = (here + step) % data.ncols;
	    ntheta = if (takestep) ttheta else theta;
	} else {
	    step = math.min(if (test.explin) (step*2) else (step + size), data.ncols);
	}
	istep += 1;
    }
    (there, ntheta, mean(ll).dv);
};

def dosimm(mod:MHmodel, test:MHtestType, size:Int, nsamps:Int, acc:Double):(DMat,LMat,DMat) = {
    var theta = mod.initfn();
    // hist(mod.data);
    val samples = dzeros(theta.length, nsamps);
    val sizes = lzeros(1, nsamps);
    val lls = dzeros(1, nsamps);
    var here = 0;
    var i = 0;
    while (i < nsamps) {
	
	val ttheta = mod.proposalfn(theta);
	val (there, nth, ll) = dostep(mod, test, mod.data, size, here, theta, ttheta, acc);
	sizes(i) = if (there > here) (there - here) else (there - here + mod.data.ncols);
	lls(i) = ll;
	here = there;
	theta = nth;
	samples(?, i) = DMat(theta);
	i += 1;
    }
    (samples, sizes, lls);
};

class NormModel(ndim:Int, n:Int, sigma:Double, pscale:Double) extends MHmodel(ndim, n, sigma, pscale) {
    val data = dnormrnd(0, sigma, ndim, n);
    val sigmat = sigma/math.sqrt(n);
    val sigmap = sigmat*pscale/math.sqrt(ndim);
    var temp = 1.0;
    
    def initfn():Mat = {
	dnormrnd(0, sigmat * math.sqrt(temp), ndim, 1);
    };
    
    def proposalfn(theta:Mat):Mat = {
	theta + dnormrnd(0, sigmap * math.sqrt(temp), ndim, 1);
    };
    
    def evalfn(batch:Mat,theta:Mat):Mat = {
	val dd = batch - theta;
	-(n / (2 * sigma * sigma * temp)) * (dd dot dd);
    };
};


class GaussianMixture(n:Int, sigma:Double, pscale:Double) extends MHmodel(2, n, sigma, pscale) {
	
	// ndim: dimension of data set. Should be 1
	// n:    number of data point in the data set
	// sigma:std of the data 
	
	// val sigmat = sigma/math.sqrt(n);
    	// val sigmap = sigmat*pscale/math.sqrt(ndim);

	val sigma1_sq = 10.0;	
	val sigma2_sq = 1.0;
	var sigma_proposer = 0.5;
	val theta1 = 0.0;
	val theta2 = 1.0;
	val u = rand(1,n);
	val data = dzeros(1,n);
	var temp = 1.0;

	def initfn():Mat = {
		// Data Generation
		for(i <- 0 until n){
			if (u(i) < 0.5){
				data(i) = dnormrnd(theta1, sigma.toFloat,1,1)(0)
			}
			else{
				data(i) = dnormrnd(theta1+theta2, sigma.toFloat,1,1)(0)
			}
		};
		
		// Initialize parameters
		val res = dones(2,1);
		res(0) = 0.5;
		res(1) = 0.0;
		res;
	};

	def proposalfn(theta:Mat):Mat ={
		theta +  dnormrnd(0, sigma_proposer, 2, 1);
	};

	def evalfn(batch:Mat, theta:Mat) : Mat = {
		val dd1 = batch - theta(0);
		val dd2 = batch - theta(0) - theta(1);
		val scale_and_temp = 1.0 * (n/temp);
		val log_term = ln( exp( -0.5 / (sigma * sigma) * ( dd1 dot dd1) ) + exp( -0.5 / (sigma * sigma) * (dd2 dot dd2) ) );
		scale_and_temp * log_term;
	};

};


def acceptrate(theta:Mat):Double = {
	val diff = abs(theta(?,1->(theta.ncols)) - theta(?,0->(theta.ncols-1)));
	return mean(sum(diff)>0.0).dv;
};		

val nsamps = 2000
val n = 100000
val sigma = math.sqrt(2)
val pscale = 1
val batchsize = 200
val sigma_proposer = 0.5;
val nn = new GaussianMixture(n = n, sigma = sigma, pscale=pscale);
// val temp_list = 1.0\2.0\50.0\200.0\500.0;
// val size_list = 50\100\200\500\1000;
// val dirname = csrow("data1.mat", "data2.mat", "data3.mat", "data4.mat", "data5.mat", "data6.mat", "data7.mat","data8.mat","data9.mat","data10.mat","data11.mat","data12.mat","data13.mat","data14.mat","data15.mat","data16.mat","data17.mat","data18.mat","data19.mat","data20.mat","data21.mat","data22.mat","data23.mat","data24.mat","data25.mat");


	
				
// for(i<- 4 until 5){
//	for(j<- 1 until 2){
	
		nn.temp = nn.n/100.0;
		nn.sigma_proposer = sigma_proposer;   // 0.4 is optimal for nsamps = 2000, minibatch size = 200	
		val newtest = new NewTest;
		val oldtest = new OldTest;
		newtest.explin = false;
		oldtest.explin = false;



		tic; 

		// mod: model, test: testtype, size: minibatch size, nsamps = number of iteration, 

		val (samples, sizes, lls) = dosimm(mod=nn, test=newtest, size=batchsize, nsamps=nsamps, acc = 0.05);
		val t1 = toc;
		val a = samples(?,(nsamps/2)->nsamps);
		scatter(a(0,?),a(1,?));
		val size1 = FMat(sizes)	
		hist(size1,50);
		val theta = samples
		val accept = acceptrate(theta);
		val progress = accept * sigma_proposer * sigma_proposer;
		print(accept); 
		print("  ");
		print(sigma_proposer); 
		print("  ");
		println(progress);


		val (samples2, sizes2, lls2) = dosimm(mod=nn, test=oldtest, size=batchsize, nsamps=nsamps, acc = 0.05);
		val t2 = toc - t1;
		val b = samples2(?,(nsamps/2)->nsamps);
		scatter(b(0,?),b(1,?));
		val size2 = FMat(sizes2)
		hist(size2,50);
		val theta2 = samples2
		val accept2 = acceptrate(theta2);
		val progress2 = accept2 * sigma_proposer * sigma_proposer;
		print(accept2); 
		print("  ");
		print(sigma_proposer); 
		print("  ");
		println(progress2);
	
		val accelerate = sum(size2)/sum(size1);		
	
	//	val filename = dirname(i*5 + j);
	//	saveAs(filename,size1,"newtest",size2,"oldtest");
	//	println("Finished i=%d, j=%d" format(i,j));

//	}
// }
