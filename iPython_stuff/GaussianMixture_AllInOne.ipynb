{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixture of Gaussians model posterior distribution estimation based on:\n",
    "\n",
    "(1) Our MH test\n",
    "\n",
    "(2) Korattikara's paper: Cutting the MH Budget\n",
    "\n",
    "(3) Bardenet's paper: On Markov chain Monte Carlo methods for tall data\n",
    "\n",
    "(4) Bardenet's paper: Towards scaling up Markov chain Monte Carlo: an adaptive subsampling approach\n",
    "\n",
    "The mixture model is based on Section 5.1 of \"Bayesian Learning via Stochastic Gradient Langevin Dynamics\" (2011). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "from scipy.stats import t\n",
    "import sys\n",
    "import scipy.io\n",
    "from bisect import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our MH Test\n",
    "class our_mh:\n",
    "    def __init__(self, x, ecdfmat, sd_vect):\n",
    "        self.X = x  # data\n",
    "        self.N = x.shape[0]\n",
    "        self.ecdfmat = ecdfmat\n",
    "        self.sd_vect = sd_vect\n",
    "    \n",
    "    def randomWalkProposer(self, theta, eps_sq):\n",
    "        # random walk proposer to get the next parameter set\n",
    "        # input: theta: 1-D Array like, of length 2\n",
    "        #        eps_sq: 2-D Array like, the covariance matrix\n",
    "        noise = np.random.multivariate_normal(np.array([0,0]), eps_sq).reshape((2,1))\n",
    "        return theta + noise\n",
    "    \n",
    "    def log_f(self, theta, X, N, T):\n",
    "        \"\"\"\n",
    "        The function 'f' is the posterior:\n",
    "    \n",
    "        f(theta) \\propto p(\\theta) * \\prod_{i=1}^N p(x_i | \\theta)\n",
    "        \"\"\"\n",
    "        scale_and_temp = N / float(len(X) * T)\n",
    "    \n",
    "        inverse_covariance = np.array([[0.1,0],[0,1]])\n",
    "        prior_constant = 1.0 / (2*np.pi*np.sqrt(10))\n",
    "        prior = np.log(prior_constant) - 0.5*(theta.T).dot(inverse_covariance).dot(theta)\n",
    "    \n",
    "        X_all = X.reshape((len(X),1))\n",
    "        ll_constant = (1.0 / (4*np.sqrt(np.pi)))\n",
    "        L = ll_constant * (np.exp(-0.25*(X_all-theta[0])**2) + \\\n",
    "                           np.exp(-0.25*(X_all-(theta[0]+theta[1]))**2))\n",
    "        log_likelihood = np.sum(np.log(L)) * scale_and_temp\n",
    "    \n",
    "        assert (N / float(len(X))) >= 1\n",
    "        assert not np.isnan(prior + log_likelihood)\n",
    "        return (prior + log_likelihood)[0,0]\n",
    "    \n",
    "    def get_delta(self, theta_c, theta_p, X, N, T):\n",
    "        loss_old = self.log_f(theta_c, X, N, T)\n",
    "        loss_new = self.log_f(theta_p, X, N, T)\n",
    "        assert not np.isnan(loss_new - loss_old)\n",
    "        return loss_new - loss_old\n",
    "\n",
    "    def estimateVar_from_one_batch (self, theta_c, theta_p, X, N, T):\n",
    "        n = len(X)\n",
    "        # notice here, we need to set up the N and T to be 1, and rescale them later \n",
    "        tmp_delta = [self.get_delta(theta_c, theta_p, np.asarray([x]), 1, 1) for x in X]\n",
    "        varRes = np.var(np.asarray(tmp_delta))\n",
    "        varRes = varRes * (1.0*N/n/T)**2.0 *n\n",
    "        assert not np.isnan(varRes)\n",
    "        return varRes\n",
    "    \n",
    "    def update_delta_and_sd_one_more_minibatch(self, theta_c, theta_p, X, n, N, T, old_delta, old_sd_delta):\n",
    "        newDelta = self.get_delta(theta_c, theta_p, X, N, T)\n",
    "        updated_delta = (old_delta * n + newDelta)*1.0 / (n+1)\n",
    "        newVar = self.estimateVar_from_one_batch(theta_c, theta_p, X, N, T)\n",
    "        m = len(X)\n",
    "        updated_sd = ((old_sd_delta**2.0 *(n*m)**2 + newVar* m**2) / (m*(n+1))**2)**0.5\n",
    "        return (updated_delta, updated_sd)\n",
    "    \n",
    "    def get_rand_xcorr(self, ecdf, sdvect, estimated_sd):\n",
    "        index = bisect(sdvect, estimated_sd) + 1\n",
    "        x = ecdf[0,:]\n",
    "        f = ecdf[index, :]\n",
    "        u = np.random.random()\n",
    "        return x[bisect(f, u)]\n",
    "    \n",
    "    def posterior_estimation(self, num_passes, \\\n",
    "                             rw_eps, temperature, \\\n",
    "                             mb_size, theta, \\\n",
    "                             num_samples_delta, \\\n",
    "                             mavg):\n",
    "        our_MH_accept_1 = []\n",
    "        our_MH_reject_1 = []\n",
    "        our_sds_1 = []\n",
    "        our_deltas_1 = []\n",
    "        our_xcorrs_1 = []\n",
    "        data_consume = []\n",
    "        all_3 = theta\n",
    "        sd = 0\n",
    "        \n",
    "        for T in range(1, num_passes):  \n",
    "            if (T % int(num_passes/4) == 0):\n",
    "                print(\"T={}\".format(T))\n",
    "            theta_new = self.randomWalkProposer(theta, rw_eps)\n",
    "            X_mb_real = self.X[np.random.choice(self.N, mb_size, replace=False)]\n",
    "            delta_real = self.get_delta(theta, theta_new, X_mb_real, self.N, temperature)\n",
    "            \n",
    "            X_mini_batch = X[np.random.choice(self.N, mb_size, replace=False)]\n",
    "            this_est_std = self.estimateVar_from_one_batch(theta, theta_new, X_mini_batch, self.N, temperature)**0.5\n",
    "            projected_mavg = this_est_std\n",
    "            num_mini_batch = 1\n",
    "            while (projected_mavg >= 1.188):\n",
    "                # we need to consume more data here\n",
    "                X_new_mini_batch = X[np.random.choice(self.N, mb_size, replace=False)]\n",
    "                updatedval = self.update_delta_and_sd_one_more_minibatch(theta, theta_new, X_new_mini_batch,\\\n",
    "                                                                         num_mini_batch, self.N, temperature, delta_real,\\\n",
    "                                                                        projected_mavg)\n",
    "                projected_mavg = updatedval[1]\n",
    "                delta_real = updatedval[0]\n",
    "                num_mini_batch += 1\n",
    "        \n",
    "            data_consume.append(num_mini_batch)\n",
    "            # Now we update the moving average and take advantage of pre-computed data.\n",
    "            sd = projected_mavg\n",
    "            X_corr = self.get_rand_xcorr(self.ecdfmat, self.sd_vect, sd)\n",
    "    \n",
    "      \n",
    "            # Gather data for diagnostics.\n",
    "            our_deltas_1.append(delta_real)\n",
    "            our_sds_1.append(sd)\n",
    "            our_xcorrs_1.append(X_corr)\n",
    "    \n",
    "            # Now *finally* do the test!\n",
    "            if (X_corr + delta_real > 0):\n",
    "                theta = theta_new\n",
    "                our_MH_accept_1.append(T)\n",
    "            else:\n",
    "                our_MH_reject_1.append(T)\n",
    "            all_3 = np.concatenate((all_3,theta), axis=1)\n",
    "        return (all_3, data_consume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class cut_mh:\n",
    "#    def __init__(self):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate data\n",
    "N = 10000 # number of points\n",
    "sigma1_sq = 10\n",
    "sigma2_sq = 1\n",
    "sigmax_sq = 2\n",
    "theta1 = 0\n",
    "theta2 = 1\n",
    "X = np.zeros(N)\n",
    "i = 0\n",
    "while i < N :\n",
    "    u = np.random.random()\n",
    "    if (u<0.5):\n",
    "        X[i] = np.random.normal(theta1, np.sqrt(sigmax_sq))\n",
    "        i = i + 1\n",
    "    elif (u>0.5):\n",
    "        X[i] = np.random.normal(theta1+theta2, np.sqrt(sigmax_sq))\n",
    "        i = i + 1\n",
    "        \n",
    "# Load XcorrCurves.mat\n",
    "mat = scipy.io.loadmat('../generateXcorr/XcorrCurves.mat')\n",
    "ecdfmat = mat['res']\n",
    "sd_vect = mat['sdval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature and minibatch size are:\n",
      "10 50\n"
     ]
    }
   ],
   "source": [
    "# *********** Run Our MH Test **********\n",
    "num_passes = 1000\n",
    "rw_eps = 0.03 * np.eye(2)\n",
    "temperature = 110\n",
    "mb_size = 200\n",
    "theta = np.array([[0.5],[0]])\n",
    "num_samples_delta = 5\n",
    "mavg = 0.7\n",
    "mhtest = our_mh(X, ecdfmat, sd_vect)\n",
    "\n",
    "# iterate using different temperature and mb_size\n",
    "for temperature in range(10,150,10):\n",
    "    for mb_size in range(50,500,50):\n",
    "        print 'Temperature and minibatch size are:' \n",
    "        print temperature, mb_size\n",
    "        (all3, data_consume) = mhtest.posterior_estimation(num_passes, \\\n",
    "                             rw_eps, temperature, \\\n",
    "                             mb_size, theta, \\\n",
    "                             num_samples_delta, \\\n",
    "                             mavg)\n",
    "        # plot result\n",
    "        fig, axarr = plt.subplots(1,2,figsize=(15,5))\n",
    "        axarr[0].set_title(\"Our Method\", size=\"x-large\")\n",
    "        axarr[0].scatter(all3[0], all3[1])\n",
    "        axarr[0].set_xlim([-1.5,2.5])\n",
    "        axarr[0].set_ylim([-3,3])\n",
    "        dataconsume = np.asarray(data_consume)\n",
    "        axarr[1].set_title(\"Data Instances Consumed Per Iteration\", size=\"xx-large\")\n",
    "        axarr[1].hist(dataconsume*200, bins=10, facecolor ='green')\n",
    "        axarr[1].set_xlabel(\"Data Instances\", size=\"x-large\")\n",
    "        axarr[1].set_ylabel(\"Counts\", size=\"x-large\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
