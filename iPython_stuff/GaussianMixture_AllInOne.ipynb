{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixture of Gaussians model posterior distribution estimation based on:\n",
    "\n",
    "(1) Our MH test\n",
    "\n",
    "(2) Korattikara's paper: Cutting the MH Budget\n",
    "\n",
    "(3) Bardenet's paper: On Markov chain Monte Carlo methods for tall data\n",
    "\n",
    "(4) Bardenet's paper: Towards scaling up Markov chain Monte Carlo: an adaptive subsampling approach\n",
    "\n",
    "The mixture model is based on Section 5.1 of \"Bayesian Learning via Stochastic Gradient Langevin Dynamics\" (2011). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "from scipy.stats import t\n",
    "import sys\n",
    "import scipy.io\n",
    "from bisect import bisect\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our MH Test\n",
    "class our_mh:\n",
    "    def __init__(self, x, ecdfmat, sd_vect):\n",
    "        self.X = x  # data\n",
    "        self.N = x.shape[0]\n",
    "        self.ecdfmat = ecdfmat\n",
    "        self.sd_vect = sd_vect\n",
    "    \n",
    "    def randomWalkProposer(self, theta, eps_sq):\n",
    "        # random walk proposer to get the next parameter set\n",
    "        # input: theta: 1-D Array like, of length 2\n",
    "        #        eps_sq: 2-D Array like, the covariance matrix\n",
    "        noise = np.random.multivariate_normal(np.array([0,0]), eps_sq).reshape((2,1))\n",
    "        return theta + noise\n",
    "    \n",
    "    def log_f(self, theta, X, N, T):\n",
    "        \"\"\"\n",
    "        The function 'f' is the posterior:\n",
    "    \n",
    "        f(theta) \\propto p(\\theta) * \\prod_{i=1}^N p(x_i | \\theta)\n",
    "        \"\"\"\n",
    "        scale_and_temp = N / float(len(X) * T)\n",
    "    \n",
    "        inverse_covariance = np.array([[0.1,0],[0,1]])\n",
    "        prior_constant = 1.0 / (2*np.pi*np.sqrt(10))\n",
    "        prior = np.log(prior_constant) - 0.5*(theta.T).dot(inverse_covariance).dot(theta)\n",
    "    \n",
    "        X_all = X.reshape((len(X),1))\n",
    "        ll_constant = (1.0 / (4*np.sqrt(np.pi)))\n",
    "        L = ll_constant * (np.exp(-0.25*(X_all-theta[0])**2) + \\\n",
    "                           np.exp(-0.25*(X_all-(theta[0]+theta[1]))**2))\n",
    "        log_likelihood = np.sum(np.log(L)) * scale_and_temp\n",
    "    \n",
    "        assert (N / float(len(X))) >= 1\n",
    "        assert not np.isnan(prior + log_likelihood)\n",
    "        return (prior + log_likelihood)[0,0]\n",
    "    \n",
    "    def get_delta(self, theta_c, theta_p, X, N, T):\n",
    "        loss_old = self.log_f(theta_c, X, N, T)\n",
    "        loss_new = self.log_f(theta_p, X, N, T)\n",
    "        assert not np.isnan(loss_new - loss_old)\n",
    "        return loss_new - loss_old\n",
    "\n",
    "    def estimateVar_from_one_batch (self, theta_c, theta_p, X, N, T):\n",
    "        n = len(X)\n",
    "        # notice here, we need to set up the N and T to be 1, and rescale them later \n",
    "        tmp_delta = [self.get_delta(theta_c, theta_p, np.asarray([x]), 1, 1) for x in X]\n",
    "        varRes = np.var(np.asarray(tmp_delta))\n",
    "        varRes = varRes * (1.0*N/n/T)**2.0 *n\n",
    "        assert not np.isnan(varRes)\n",
    "        return varRes\n",
    "    \n",
    "    def update_delta_and_sd_one_more_minibatch(self, theta_c, theta_p, X, n, N, T, old_delta, old_sd_delta):\n",
    "        newDelta = self.get_delta(theta_c, theta_p, X, N, T)\n",
    "        updated_delta = (old_delta * n + newDelta)*1.0 / (n+1)\n",
    "        newVar = self.estimateVar_from_one_batch(theta_c, theta_p, X, N, T)\n",
    "        m = len(X)\n",
    "        updated_sd = ((old_sd_delta**2.0 *(n*m)**2 + newVar* m**2) / (m*(n+1))**2)**0.5\n",
    "        return (updated_delta, updated_sd)\n",
    "    \n",
    "    def get_rand_xcorr(self, ecdf, sdvect, estimated_sd):\n",
    "        index = bisect(sdvect, estimated_sd) + 1\n",
    "        x = ecdf[0,:]\n",
    "        f = ecdf[index, :]\n",
    "        u = np.random.random()\n",
    "        return x[bisect(f, u)]\n",
    "    \n",
    "    def posterior_estimation(self, num_passes, \\\n",
    "                             rw_eps, temperature, \\\n",
    "                             mb_size, theta, \\\n",
    "                             num_samples_delta, \\\n",
    "                             mavg):\n",
    "        our_MH_accept_1 = []\n",
    "        our_MH_reject_1 = []\n",
    "        our_sds_1 = []\n",
    "        our_deltas_1 = []\n",
    "        our_xcorrs_1 = []\n",
    "        data_consume = []\n",
    "        all_3 = theta\n",
    "        sd = 0\n",
    "        \n",
    "        for T in range(1, num_passes):  \n",
    "            if (T % int(num_passes/4) == 0):\n",
    "                print(\"T={}\".format(T))\n",
    "            theta_new = self.randomWalkProposer(theta, rw_eps)\n",
    "            X_mb_real = self.X[np.random.choice(self.N, mb_size, replace=False)]\n",
    "            delta_real = self.get_delta(theta, theta_new, X_mb_real, self.N, temperature)\n",
    "            \n",
    "            X_mini_batch = X[np.random.choice(self.N, mb_size, replace=False)]\n",
    "            this_est_std = self.estimateVar_from_one_batch(theta, theta_new, X_mini_batch, self.N, temperature)**0.5\n",
    "            projected_mavg = this_est_std\n",
    "            num_mini_batch = 1\n",
    "            while (projected_mavg >= 1.188):\n",
    "                # we need to consume more data here\n",
    "                X_new_mini_batch = X[np.random.choice(self.N, mb_size, replace=False)]\n",
    "                updatedval = self.update_delta_and_sd_one_more_minibatch(theta, theta_new, X_new_mini_batch,\\\n",
    "                                                                         num_mini_batch, self.N, temperature, delta_real,\\\n",
    "                                                                        projected_mavg)\n",
    "                projected_mavg = updatedval[1]\n",
    "                delta_real = updatedval[0]\n",
    "                num_mini_batch += 1\n",
    "        \n",
    "            data_consume.append(num_mini_batch)\n",
    "            # Now we update the moving average and take advantage of pre-computed data.\n",
    "            sd = projected_mavg\n",
    "            X_corr = self.get_rand_xcorr(self.ecdfmat, self.sd_vect, sd)\n",
    "    \n",
    "      \n",
    "            # Gather data for diagnostics.\n",
    "            our_deltas_1.append(delta_real)\n",
    "            our_sds_1.append(sd)\n",
    "            our_xcorrs_1.append(X_corr)\n",
    "    \n",
    "            # Now *finally* do the test!\n",
    "            if (X_corr + delta_real > 0):\n",
    "                theta = theta_new\n",
    "                our_MH_accept_1.append(T)\n",
    "            else:\n",
    "                our_MH_reject_1.append(T)\n",
    "            all_3 = np.concatenate((all_3,theta), axis=1)\n",
    "        return (all_3, data_consume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bardenet's 14' Paper\n",
    "class adaptive_mh14:\n",
    "    def __init__(self,x):\n",
    "        self.X = x\n",
    "        self.N = x.shape[0]\n",
    "    \n",
    "    def randomWalkProposer(self, theta, eps_sq):\n",
    "        noise = np.random.multivariate_normal(np.array([0,0]), eps_sq).reshape((2,1))\n",
    "        return theta + noise\n",
    "    \n",
    "    def log_p(self, theta, theta_var):\n",
    "        '''\n",
    "        log prior : log(p(\\theta))\n",
    "        '''\n",
    "        Sigma = np.array([[theta_var[0],0],[0,theta_var[1]]])\n",
    "        res_first_part = -1.0 * np.log( 2 * np.pi * np.sqrt(np.linalg.det(Sigma)) ) \n",
    "        res_second_part = -0.5 * (theta.T).dot(np.linalg.inv(Sigma)).dot(theta)\n",
    "        return res_first_part + res_second_part\n",
    "        \n",
    "    \n",
    "    def log_ll(self, X, theta, var_X):\n",
    "        '''\n",
    "        function to calculate log likelihood term: \\sum_{i=1}^b{log(p(x_i|\\theta))}\n",
    "        input: var_X : variance of x : var_X = 2\n",
    "        '''\n",
    "        X_all = X.reshape((len(X),1))\n",
    "        ll_constant = 1.0 / (np.sqrt(2.0 * np.pi * var_X) * 2.0 )\n",
    "        L = ll_constant * ( np.exp(-0.5/var_X * (X_all-theta[0])**2) + \\\n",
    "                           np.exp(-0.5/var_X *(X_all-(theta[0]+theta[1]))**2) )\n",
    "        log_likelihood = np.sum(np.log(L))\n",
    "        return log_likelihood\n",
    "    \n",
    "    def calculate_c_theta(self, theta_c, theta_p, var_X):\n",
    "        '''\n",
    "        function to calculate C_{\\theta, \\theta'} according to the paper\n",
    "        '''\n",
    "        res = 0\n",
    "        for i in range(self.N):\n",
    "            x = np.array([[self.X[i]]])\n",
    "            temp = np.abs( self.log_ll(x, theta_c, var_X) - self.log_ll(x, theta_p, var_X) )\n",
    "            if temp > res :\n",
    "                res = temp\n",
    "        return res\n",
    "  \n",
    "    def function_phi(self, theta_c, theta_p, theta_var):\n",
    "        '''\n",
    "        function_phi = 1/n * log[ u * p(\\theta) / p(\\theta')]\n",
    "        since we use a random walk proposer, so q(\\theta'|\\theta) = q(\\theta|\\theta')\n",
    "        \n",
    "        input: theta_c: current theta value\n",
    "               theta_p: proposed theta value\n",
    "               theta_var: variance of theta : [10,1]\n",
    "        '''\n",
    "        u = np.random.random()\n",
    "        phi = 1/self.N * ( np.log(u) + self.log_p(theta_c, theta_var) - self.log_p(theta_p, theta_var) )\n",
    "        return phi\n",
    "    \n",
    "    def posterior_estimation(self, num_pass, theta_start, eps_sq, theta_var, var_X, p, delta, gamma):\n",
    "        '''\n",
    "        function to perform posteriro estimation\n",
    "        input: b : minibatch size\n",
    "               p : a value to calculate delta_t\n",
    "        '''\n",
    "        theta = theta_start\n",
    "        theta_list = copy.deepcopy(theta_start)\n",
    "        batch_size = []\n",
    "        for k in range(num_pass):\n",
    "            data = self.X\n",
    "            N = data.shape[0]\n",
    "            theta_new = self.randomWalkProposer(theta, eps_sq)\n",
    "            phi = self.function_phi(theta, theta_new, theta_var)\n",
    "            t = 0\n",
    "            t_look = 0\n",
    "            A_star = 0\n",
    "            b = 1   # initialize batchsize to 1\n",
    "            done = False\n",
    "            while done == False:\n",
    "                sample_index = np.random.choice(data.shape[0], b-t, replace=False)\n",
    "                X_mini = data[sample_index]\n",
    "                data = np.delete(data, sample_index)\n",
    "                A_star = 1.0 / b * ( t*A_star + self.log_ll(X_mini,theta_new,var_X)\\\n",
    "                                    - self.log_ll(X_mini, theta, var_X) )\n",
    "                t = copy.deepcopy(b)\n",
    "                \n",
    "                CTT =  self.calculate_c_theta(theta, theta_new, var_X)\n",
    "                ft = (len(X_mini) -1)/self.N\n",
    "                delta_t_look = (p-1)/(p * np.power(t_look,p) ) * delta\n",
    "                \n",
    "                c = 2 * CTT * np.sqrt( ((1- ft) * np.log(2/delta_t_look)) / (2*t) )\n",
    "                \n",
    "                t_look = t_look + 1\n",
    "                \n",
    "                b = min(self.N, gamma * t)\n",
    "                \n",
    "                if np.abs(A_star - phi) >= c or b >= self.N :\n",
    "                    done = True\n",
    "            if A_star > phi :\n",
    "                theta = theta_new\n",
    "            else:\n",
    "                theta = theta\n",
    "            theta_list = np.concatenate((theta_list, theta), axis=1)\n",
    "            batch_size.append(b)\n",
    "        return (theta_list, batch_size)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cutting the MH Budget Method\n",
    "class cut_mh:\n",
    "    def __init__(self,x):\n",
    "        self.X = x\n",
    "        self.N = x.shape[0]\n",
    "        \n",
    "    def randomWalkProposer(self, theta, eps_sq):\n",
    "        # random walk proposer to get the next parameter set\n",
    "        # input: theta: 1-D Array like, of length 2\n",
    "        #        eps_sq: 2-D Array like, the covariance matrix\n",
    "        noise = np.random.multivariate_normal(np.array([0,0]), eps_sq).reshape((2,1))\n",
    "        return theta + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate data\n",
    "N = 10000 # number of points\n",
    "sigma1_sq = 10\n",
    "sigma2_sq = 1\n",
    "sigmax_sq = 2\n",
    "theta1 = 0\n",
    "theta2 = 1\n",
    "X = np.zeros(N)\n",
    "i = 0\n",
    "while i < N :\n",
    "    u = np.random.random()\n",
    "    if (u<0.5):\n",
    "        X[i] = np.random.normal(theta1, np.sqrt(sigmax_sq))\n",
    "        i = i + 1\n",
    "    elif (u>0.5):\n",
    "        X[i] = np.random.normal(theta1+theta2, np.sqrt(sigmax_sq))\n",
    "        i = i + 1\n",
    "        \n",
    "# Load XcorrCurves.mat\n",
    "mat = scipy.io.loadmat('../generateXcorr/XcorrCurves.mat')\n",
    "ecdfmat = mat['res']\n",
    "sd_vect = mat['sdval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature and minibatch size are:\n",
      "10 50\n",
      "T=2500\n",
      "T=5000\n"
     ]
    }
   ],
   "source": [
    "# *********** Run Our MH Test **********\n",
    "num_passes = 10000\n",
    "rw_eps = 0.03 * np.eye(2)\n",
    "temperature = 110\n",
    "mb_size = 200\n",
    "theta = np.array([[0.5],[0]])\n",
    "num_samples_delta = 5\n",
    "mavg = 0.7\n",
    "mhtest = our_mh(X, ecdfmat, sd_vect)\n",
    "\n",
    "# iterate using different temperature and mb_size\n",
    "for temperature in range(10,150,10):\n",
    "    for mb_size in range(50,500,50):\n",
    "        print 'Temperature and minibatch size are:' \n",
    "        print temperature, mb_size\n",
    "        (all3, data_consume) = mhtest.posterior_estimation(num_passes, \\\n",
    "                             rw_eps, temperature, \\\n",
    "                             mb_size, theta, \\\n",
    "                             num_samples_delta, \\\n",
    "                             mavg)\n",
    "        # plot result\n",
    "        fig, axarr = plt.subplots(1,2,figsize=(15,5))\n",
    "        axarr[0].set_title(\"Our Method\", size=\"x-large\")\n",
    "        axarr[0].scatter(all3[0], all3[1])\n",
    "        axarr[0].set_xlim([-1.5,2.5])\n",
    "        axarr[0].set_ylim([-3,3])\n",
    "        dataconsume = np.asarray(data_consume)\n",
    "        axarr[1].set_title(\"Data Instances Consumed Per Iteration\", size=\"xx-large\")\n",
    "        axarr[1].hist(dataconsume*200, bins=10, facecolor ='green')\n",
    "        axarr[1].set_xlabel(\"Data Instances\", size=\"x-large\")\n",
    "        axarr[1].set_ylabel(\"Counts\", size=\"x-large\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ************** Run Bardenet 14' Paper *************\n",
    "num_passes = 10000\n",
    "rw_eps = 0.03 * np.eye(2)\n",
    "theta_start = np.array([[0.5],[0]])\n",
    "theta_var = np.array([[10],[1]])\n",
    "var_X = 2\n",
    "p = 2 # according to the paper p > 1, delta = 0.01, gamma= 2\n",
    "delta = 0.01\n",
    "gamma = 2 \n",
    "bard_test = adaptive_mh14(X)\n",
    "\n",
    "# do estimation\n",
    "(posterior, data_consume) = \\\n",
    "bard_test.posterior_estimation(num_passes, theta_start, rw_eps, theta_var, var_X, p, delta, gamma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
