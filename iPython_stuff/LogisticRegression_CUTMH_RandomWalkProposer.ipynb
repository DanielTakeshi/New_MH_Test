{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import *\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import t\n",
    "from bisect import bisect\n",
    "import scipy.io\n",
    "import copy\n",
    "from scipy.stats import norm\n",
    "import numpy.matlib\n",
    "%pylab inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook implements the Logistic Regression in the \n",
    "\"Cutting the Metropolis Hastings Budget\" framework. \n",
    "\n",
    "The target distribution is the posterior for a logistic regression\n",
    "model trained on MNIST dataset for classifying digits 7 vs 9. The \n",
    "dataset consisted of 12214 datapoints and we reduced the dimensionality\n",
    "using PCA. \n",
    "\"\"\"\n",
    "\n",
    "# get input data\n",
    "\n",
    "mat = scipy.io.loadmat('minist7vs1.mat')\n",
    "TrainLabel = mat['TrainLabel']\n",
    "TrainLabel = np.reshape(TrainLabel, TrainLabel.shape[1],1)\n",
    "TrainImg = mat['TrainImg']\n",
    "# TestImg = mat['TestImg']\n",
    "# TestLabel = mat['TestLabel']\n",
    "print TrainLabel.shape\n",
    "print TrainImg.shape\n",
    "print type(TrainLabel)\n",
    "print type(TrainImg)\n",
    "print TrainImg[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cutting the Metropolis Hastings Budget Method\n",
    "\"\"\"\n",
    "def random_walk_proposer(beta_t, sigmarw):\n",
    "    \"\"\"\n",
    "    Input: beta_t  : previous parameters, 1-D array\n",
    "           sigmarw : standard deviation, 1-D array\n",
    "    \"\"\"\n",
    "    res = (np.random.multivariate_normal(beta_t, np.diag(sigmarw))).reshape((len(beta_t),))\n",
    "    return res\n",
    "\n",
    "def ll_data(beta_t, beta_n, X, Y):\n",
    "    p_x_beta_t = 1/(1 + exp(-1* Y*np.dot(beta_t,X)))\n",
    "    p_x_beta_n = 1/(1 + exp(-1* Y*np.dot(beta_n,X)))\n",
    "    return log(p_x_beta_n) - log(p_x_beta_t)\n",
    "\n",
    "def eval_U0(N):\n",
    "    u = np.random.random()\n",
    "    return 1/N*log(u)\n",
    "\n",
    "def make_decision(l_list, N, U0):\n",
    "    n = float(len(l_list))\n",
    "    l_mean = sum(l_list)/n\n",
    "    l_sq = ((np.array(l_list))**2).tolist()\n",
    "    l_sq_mean = sum(l_sq)/n\n",
    "    sl = sqrt((l_sq_mean - l_mean*l_mean)*n/(n-1))\n",
    "    s = sl/sqrt(n) * sqrt(1 - (n-1)/(N-1))\n",
    "    t_stats = abs((l_mean - U0)/s)\n",
    "    delta = 1 - t.cdf(t_stats, n-1)\n",
    "    return delta\n",
    "    \n",
    "def generate_parameter(beta_t, N, sigmarw, X, Y, batchsize, epsilon ):\n",
    "    U0 = eval_U0(N)\n",
    "    # generate new parameter\n",
    "    P = len(X[0])\n",
    "    sigma = (np.matlib.repmat(sigmarw, P,1)).reshape(P,)\n",
    "    beta_n = random_walk_proposer(beta_t, sigma)\n",
    "    \n",
    "    # make decision\n",
    "    l_list = []\n",
    "    for i in range(batchsize):\n",
    "        mid = ll_data(beta_t, beta_n, X[i], Y[i])\n",
    "        l_list.append(mid)\n",
    "    \n",
    "    pos = batchsize\n",
    "    delta = make_decision(l_list, N, U0)\n",
    "    while (delta>epsilon) and (pos < N):\n",
    "        mid = ll_data(beta_t, beta_n, X[pos], Y[pos])\n",
    "        l_list.append(mid)\n",
    "        pos = pos + 1\n",
    "        delta = make_decision(l_list, N, U0)\n",
    "    \n",
    "    l_mean = sum(l_list)/float(len(l_list))\n",
    "    if l_mean > U0:\n",
    "        return (beta_n,1)\n",
    "    else:\n",
    "        return (beta_t,0)\n",
    "    \n",
    "def eval_cost(X,Y,beta):\n",
    "    N = len(Y)\n",
    "    cost = 0\n",
    "    for i in range(N):\n",
    "        sigmoid = 1/(1 + exp(-1* Y[i]*np.dot(beta,X[i])))\n",
    "        if sigmoid < 0.5 : \n",
    "            cost = cost + 1\n",
    "    return log(cost/float(N))\n",
    "    \n",
    "def train(X, Y, sigmarw, batchsize, epsilon, niter):\n",
    "    N = len(Y) # number of total training data\n",
    "    P = len(X[0]) # parameter dimension\n",
    "    beta_t = np.ones(P)\n",
    "    cost_list = []\n",
    "    accept = []\n",
    "    for i in range(niter):\n",
    "        index = np.random.permutation(N)\n",
    "        X = X[index]\n",
    "        Y = Y[index]\n",
    "        (beta_t, mid) = generate_parameter(beta_t, N, sigmarw, X,Y,batchsize,epsilon)\n",
    "        cost = eval_cost(X,Y,beta_t)\n",
    "        cost_list.append(cost)\n",
    "    return cost_list\n",
    "\n",
    "X = TrainImg\n",
    "Y = TrainLabel\n",
    "sigmarw = 0.01\n",
    "batchsize = 50\n",
    "epsilon = 0.02\n",
    "niter = 2000\n",
    "cost_list = train(X, Y, sigmarw, batchsize, epsilon, niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(cost_list)\n",
    "plt.show()\n",
    "print len(cost_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following part implements the logistic regression using our propsed Metropolis Hasitings Test Method\n",
    "\n",
    "delta = log(f(\\theta_t)p(\\theta_p|theta_t)/f(\\theta_p)/p(\\theta_t|theta_p))\n",
    "\n",
    "where f_\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
